{
    "00050f7365e317dc0487e282a4c33804b58b1fb3": "Yes",
    "003d6f9722ddc2ee13e879fefafc315fb8e87cb9": "The two networks are similar to each other.",
    "005cca3c8ab6c3a166e315547a2259020f318ffb": "we define the task of machine reading comprehension, the target application of the proposed methodology as follows: Totally defined qualitative analysis (Table1)",
    "007b13f05d234d37966d1aa7d85b5fd78564ff45": "No",
    "009ce6f2bea67e7df911b3f93443b23467c9f4a1": "Translation accuracy is 86.66%.\nTranslation accuracy is 86.66",
    "00c57e45ac6afbdfa67350a57e81b4fad0ed2885": "Yes",
    "0101ebfbaba75fd47868ad0c796ac44ebc19c566": "1) The similarity mapping layer which converts the input passage, query and choice into feature representation and perform a similarity operation to each other.",
    "01209a3bead7c87bcdc628be2a5a26b41abde9d1": "SNLI BIBREF22 , MultiNLI BIBREF23 , Quora Question Pairs",
    "012b8a89aea27485797373adbcda32f16f9d7b54": "BIBREF16, BIBREF26, BIBREF26",
    "01a41c0a4a7365cd37d28690735114f2ff5229f2": "Unanswerable",
    "01e2d10178347d177519f792f86f25575106ddc7": "AUD, each spoken document is represented a vector of unigrams, or bag of acoustic unit,  words or phones",
    "01f4a0a19467947a8f3bdd7ec9fac75b5222d710": "RNNGs with induced trees, we use the parameterization and hyperparameters from BIBREF17 , RNNGs",
    "021bfb7e180d67112b74f05ecb3fa13acc036c86": "Unanswerable",
    "022c365a14fdec406c7a945a1a18e7e79df37f08": "1) Encoding the speech encoder with attention module and decoder to generate directed MT encoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder decoder dec",
    "02428a8fec9788f6dc3a86b5d5f3aa679935678d": "We evaluate our methods on several frequently used datasets whose themes range from sentiment, web-page, healthcare to healthcare to healthcare to healthcare to healthcare to healthcare to healthcare to healthcare to healthcare to healthcare to healthcare to dental.",
    "03c967763e51ef2537793db7902e2c9c17e43e95": " strong baseline BLEU from 14.19 to 16.85 ($+26.8$)",
    "03e9ac1a2d90152cd041342a11293a1ebd33bcc3": "Yes",
    "03ebb29c08375afc42a957c7b2dc1a42bed7b713": "They used the named entity recognition module after part-of-speech tagging.",
    "044f922604b4b3f42ae381419fd5cd5624fa0637": "attention and alignment match",
    "04bde1d2b445f971e97bb46ade2d0290981c7a32": "RecNN, DC-RecNN, RNTN, and TreeLSTM",
    "04d1b3b41fb62a7b896afe55e0e8bc5ffb8c6e39": "10 annotators for each word in the dataset",
    "051df74dc643498e95d16e58851701628fdfd43e": "Unanswerable",
    "05887a8466e0a2f0df4d6a5ffc5815acd7d9066a": "Galatasaray (namely Target-1) and Felipe (Fenerbah\u00e7e) (namely Target-2)",
    "05c49b9f84772e6df41f530d86c1f7a1da6aa489": "Unanswerable",
    "0602a974a879e6eae223cdf048410b5a0111665e": "Do the entity/organization, location, keyword and date distributions",
    "0682bf049f96fa603d50f0fdad0b79a5c55f6c97": "No",
    "0689904db9b00a814e3109fb1698086370a28fa2": " text embedding method, Lanchichinetti and co-workers BIBREF36",
    "06b5272774ec43ee5facfa7111033386f06cf448": "Yes",
    "06be47e2f50b902b05ebf1ff1c66051925f5c247": "No",
    "06cc8fcafc0880cf69a2514bb7341642b9833041": "Unanswerable",
    "06eb9f2320451df83e27362c22eb02f4a426a018": " levels 3, confirming that document preprocessing plays an important role in keyphrase extraction performance",
    "0737954caf66f2b4c898b356d2a3c43748b9706b": "Yes",
    "0752d71a0a1f73b3482a888313622ce9e9870d6e": "Word Error Rate (WER) is the percentage of words in the test set for which the correct guess is not in the first 100 guesses of the system.",
    "0767ca8ff1424f7a811222ca108a33b6411aaa8a": "ROGUE metric to judge the summary of the summary of the report by, we compare the final scores after the two cases- first, when we use the gold-standard AMR graphs and first when we used the CNN-Dailymail corpus",
    "07b70b2b799b9efa630e8737df8b1dd1284f032c": " eight",
    "07d15501a599bae7eb4a9ead63e9df3d55b3dc35": "By using the dataset provided by the National Science Foundation (#134427) and by the John Templeton Foundation (#48503)",
    "0810b43404686ddfe4ca84783477ae300fdd2ea4": "Fisher Phase 1",
    "08b57deb237f15061e4029b6718f1393fa26acce": "crowdworkers",
    "09a1173e971e0fcdbf2fbecb1b077158ab08f497": "Unanswerable",
    "09c86ef78e567033b725fc56b85c5d2602c1a7c3": "their model is called CBT NE+CN.",
    "0a5ffe4697913a57fda1fd5a188cd5ed59bdc5c7": "LSTM-based and lexical features",
    "0a75a52450ed866df3a304077769e1725a995bb7": "their lower layers consisting of the convolutional layers",
    "0ab3df10f0b7203e859e9b62ffa7d6d79ffbbe50": "Accuracy of best datasets",
    "0ad4359e3e7e5e5f261c2668fe84c12bc762b3b8": "the  SATA Tree-LSTM, SATA Tree-LSTM, SATA Tree-LSTM",
    "0af16b164db20d8569df4ce688d5a62c861ace0b": "Unanswerable",
    "0ba3ea93eef5660a79ea3c26c6a270eac32dfa4c": "Yes",
    "0c234db3b380c27c4c70579a5d6948e1e3b24ff1": "CoNLL\u2013SIGMORPHON 2018 baseline system, a LSTM decoder for the inputroid, for the inputroid, for the inputroid, for the inputroid, for the inputgiv.",
    "0cfe0e33fbb100751fc0916001a5a19498ae8cb5": "They used the relation classification dataset of the SemEval 2010 task 8 BIBREF8 .",
    "0d34c0812f1e69ea33f76ca8c24c23b0415ebc8d": "TDK (Turkish Language Institution) dictionary to obtain word polarity scores",
    "0d9fcc715dee0ec85132b3f4a730d7687b6a06f4": "affirmations of the effect of defenses available to the adversary by making the model susceptible to spelling attacks as they can make use of the residual word context",
    "0ec56e15005a627d0b478a67fd627a9d85c3920e": "Unanswerable",
    "0ee73909ac638903da4a0e5565c8571fc794ab96": "They used a monolingual Tamil MT ",
    "0f12dc077fe8e5b95ca9163cea1dd17195c96929": "Unanswerable",
    "0f567251a6566f65170a1329eeeb5105932036b2": "12,594 unique hashtags",
    "0f6216b9e4e59252b0c1adfd1a848635437dfcdc": "We selected the 100 words which occurred most frequently in the dataset: The data generation procedure, and the techniques and tools used.",
    "0f7867f888109b9e000ef68965df4dde2511a55f": "\nThe relation classification dataset of the SemEval 2010 task 8 ",
    "0fc2b5bc2ead08a6fe0280fb3a47477c6df1587c": "Yes",
    "1038542243efe5ab3e65c89385e53c4831cd9981": "Unanswerable",
    "1062a0506c3691a93bb914171c2701d2ae9621cb": "non-factual accounts have a unique pattern in posting tweet sequences.",
    "1088255980541382a2aa2c0319427702172bbf84": "BIBREF0 :th field INLINEFORM1",
    "1097768b89f8bd28d6ef6443c94feb04c1a1318e": "Yes",
    "10d450960907091f13e0be55f40bcb96f44dd074": "Yes",
    "10fb7dc031075946153baf0a0599e126de29e3a4": "Unanswerable",
    "111afb77cfbf4c98e0458606378fa63a0e965e36": "Unanswerable",
    "113d791df6fcfc9cecfb7b1bebaf32cc2e4402ab": "Word Error Rate (WER) is the percentage of words in the test set for which the correct guess is not in the first 100 guesses of the system.",
    "1142784dc4e0e4c0b4eca1feaf1c10dc46dd5891": "10min, an hour",
    "114934e1a1e818630ff33ac5c4cd4be6c6f75bb2": "Unanswerable",
    "1170e4ee76fa202cabac9f621e8fbeb4a6c5f094": "Yes",
    "11e8bd4abf5f8bdabad3e8f0691e6d0ad6c326af": "a new dataset based on OpenStreetMap, in which we align NL instructions to their corresponding routes",
    "12159f04e0427fe33fa05af6ba8c950f1a5ce5ea": "logistic regression",
    "1269c5d8f61e821ee0029080c5ba2500421d5fa6": "KyTea-segmented Japanese texts and pyvi-segmented Vietnamese texts",
    "126ff22bfcc14a2f7e1a06a91ba7b646003e9cf0": "the publicly available OpenSubtitles2018 corpus BIBREF12",
    "127d5ddfabec5c58832e5865cbd8ed0978c25a13": "2013",
    "12c50dea84f9a8845795fa8b8c1679328bd66246": "Fisher Phase 1 US English corpus",
    "12d7055baf5bffb6e9e95e977c000ef2e77a4362": "100%",
    "12f7fac818f0006cf33269c9eafd41bbb8979a48": "Unanswerable",
    "1329280df5ee9e902b2742bde4a97bc3e6573ff3": "No",
    "132f752169adf6dc5ade3e4ca773c11044985da4": "CrowdFlower dataset",
    "133eb4aa4394758be5f41744c60c99901b2bc01c": "Yes",
    "1462eb312944926469e7cee067dfc7f1267a2a8c": "1040",
    "149da739b1c19a157880d9d4827f0b692006aa2c": "out-of-scope query performance is less than 150 intents",
    "14b74ad5a6f5b0506511c9b454e9c464371ef8c4": "German-English",
    "14b8ae5656e7d4ee02237288372d9e682b24fdb8": "ironic style, we use denoising auto-encoder and back-translation to build up language models for both styles (section SECREF214 )",
    "1522ccedbb1f668958f24cca070f640274bc2549": "DUC and TAC208, critical",
    "154a721ccc1d425688942e22e75af711b423e086": "MCT, HIT, CNN, CNN, Trivia, CNN, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia, Trivia",
    "1591068b747c94f45b948e12edafe74b5e721047": "10K user-generated image (snap) and textual caption pairs where named entities in the captions are deleted, as well as various other topics",
    "15cdd9ea4bae8891c1652da2ed34c87bbbd0edb8": "Unanswerable",
    "15e481e668114e4afe0c78eefb716ffe1646b494": "AEM",
    "16535db1d73a9373ffe9d6eedaa2369cefd91ac4": "in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser model, in-browser modeling",
    "17a1eff7993c47c54eddc7344e7454fbe64191cd": " we use the proposed method and interpretability measurements using included in BIBREF23 , BIBREF26 , BIBREF24 ",
    "184b0082e10ce191940c1d24785b631828a9f714": "elasticsearch",
    "186b7978ee33b563a37139adff1da7d51a60f581": "closed test setting",
    "18942ab8c365955da3fd8fc901dfb1a3b65c1be1": "Machine reading corpus is a popular topic that can be unsafe for a system is a system is a system of learning which will enable developing strongest reasoning tasks. For example, the task of named entities recognition can be defined as a machine reading corpus",
    "18c5d366b1da8447b5404eab71f4cc658ba12e6f": "Bloom embedding, Rocheebling ",
    "193ee49ae0f8827a6e67388a10da59e137e7769f": "masked span terms",
    "197b276d0610ebfacd57ab46b0b29f3033c96a40": "ADWS kernel BIBREF18",
    "19b7312cfdddb02c3d4eaa40301a67143a72a35a": " For each phrase representation vector, we add in the target phrase vector, add in the target phrase vector and use it as a general representation of the target phrase",
    "19cf7884c0c509c189b1e74fe92c149ff59e444b": "Unanswerable",
    "1b1a30e9e68a9ae76af467e60cefb180d135e285": "353 conversations between nurses and patients",
    "1b1b0c71f1a4b37c6562d444f75c92eb2c727d9b": "Unanswerable",
    "1b23c4535a6c10eb70bbc95313c465e4a547db5e": "CTC-Attention",
    "1b72aa2ec3ce02131e60626639f0cf2056ec23ca": "100 annotators",
    "1bb7eb5c3d029d95d1abf9f2892c1ec7b6eef306": "character error rate, LSTM RNNs outperform generalization ability of 10000 hours, Distillation",
    "1bdc990c7e948724ab04e70867675a334fdd3051": "The recipe name as a sequence of tokens, a partial list of ingredients, and a calorie level",
    "1be54c5b3ea67d837ffba2290a40c1e720d9587f": "No",
    "1beb4a590fa6127a138f4ed1dd13d5d51cc96809": "SVM",
    "1c0ba6958da09411deded4a14dfea5be55687619": "112 pathology reports",
    "1c997c268c68149ae6fb43d83ffcd53f0e7fe57e": "Wikidata, Peters et al. BIBREF19, BIBREF19, BIBREF19",
    "1cb100182508cf55b3509283c0e2bbcd527d625e": "The data are embedded in a corpus which is prevalent in our data",
    "1d197cbcac7b3f4015416f0152a6692e881ada6c": " the question it is asked to extract relation from and the relation between the answer and other tokens that also appear in the ground truth",
    "1d3e914d0890fc09311a70de0b20974bf7f0c9fe": " Biomedical NER: Pretraining on unlabeled target text. Some examples of models are SQuADBERT, CORD-19, CORABLE, CORD-19, CORABLE, CORD-19, CORABLE, CORD-19, CORABLE, CORD-19, CORABLE, CORD-19",
    "1d9aeeaa6efa1367c22be0718f5a5635a73844bd": "CrowdFlower dataset",
    "1dac4bc5af239024566fcb0f43bb9ff1c248ecec": "Yes",
    "1dc2da5078a7e5ea82ccd1c90d81999a922bc9bf": "Yes",
    "1e185a3b8cac1da939427b55bf1ba7e768c5dae4": "phone classification and speaker recognition (details in \u00a7SECREF13), with identical task implementations are observed ",
    "1e4dbfc556cf237accb8b370de2f164fa723687b": "By simply adding a second variable number of phrases into a single sequence with a delimiter INLINEFORM0 SEP , and using it to interpolate the abstractive distribution INLINEFORM2 over the source text",
    "1e775cf30784e6b1c2b573294a82e145a3f959bb": "Unanswerable",
    "1ec152119cf756b16191b236c85522afeed11f59": "the highest the layer, the lower the more context-specific the contextualized representations.",
    "1ed49a8c07ef0ac15cfa6b7decbde6604decbd5b": "Meteor BIBREF31",
    "1eef2d2c296fdd10b08bf7b4ff7792cccf177d3b": "Unanswerable",
    "1f07e837574519f2b696f3d6fa3230af0b931e5d": "Yes",
    "1f085b9bb7bfd0d6c8cba1a9d73f08fcf2da7590": "Yes",
    "1ff0fccf0dca95a6630380c84b0422bed854269a": "CodaLab at https://bitly/353fbyn.",
    "2007bfb8f66e88a235c3a8d8c0a3b3dd88734706": "The differences are in the corpus after translation, when using text for emotion detection is that the most important question shows up-to-to-date",
    "203337c15bd1ee05763c748391d295a1f6415b9b": "2019",
    "206739417251064b910ae9e5ff096e867ee10fb8": "Saint-Dizier.2013, equipments are: LLL 2200, Forte, For, LLL 300, Forte, For, LLL 300, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte, Forte Forte, Forte, Forte Forte, Forte Forte, Forte Forte Forte, Forte Forte Forte, Forte Forte Forte Forte Forte, Forte Forte Forte Forte Forte ,te Forte Forte Forte Forte Forte Forte Forte For Saint-Dizier.2013, Forte Forte, Forte Forte Forte, Forte Forte Forte, Forte Forte Forte",
    "20e38438471266ce021817c6364f6a46d01564f2": "Unanswerable",
    "21548433abd21346659505296fb0576e78287a74": "The dataset from Twitter containing our training data",
    "218615a005f7f00606223005fef22c07057d9d77": "RNNGs with induced trees, we use the parameterization and hyperparameters from BIBREF17 , RNNGs",
    "218bc82796eb8d91611996979a4a42500131a936": "GTZAN Music-Speech dataset [17], consisting of 120 audio files (60 speech and 60 music), 60 speech and 60 music",
    "219af68afeaecabdfd279f439f10ba7c231736e4": "KyTea-segmented Japanese texts and pyvi-segmented Vietnamese texts",
    "220d11a03897d85af91ec88a9b502815c7d2b6f3": "Unanswerable",
    "2236386729105f5cf42f73cc055ce3acdea2d452": "Unanswerable",
    "223dc2b9ea34addc0f502003c2e1c1141f6b36a7": "reward constructively by improving the base rate of 50% on validation of the base dataset, TREC, SST-5 and IMDB, TREC",
    "2268c9044e868ba0a16e92d2063ada87f68b5d03": "Yes",
    "22714f6cad2d5c54c28823e7285dc85e8d6bc109": "Unanswerable",
    "22732cb9476e521452bf0538f3fdb94cf3867651": "Unanswerable",
    "22744c3bc68f120669fc69490f8e539b09e34b94": "No",
    "2275b0e195cd9cb25f50c5c570da97a4cce5dca8": "Unanswerable",
    "22815878083ebd2f9e08bc33a5e733063dac7a0f": "Unanswerable",
    "22b740cc3c8598247ee102279f96575bdb10d53f": "Yes",
    "22ccee453e37536ddb0c1c1d17b0dbac04c6c607": "Unanswerable",
    "2317ca8d475b01f6632537b95895608dc40c4415": "we compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet) to the following set of baselines:\nwe compare our approach (FacTweet",
    "23b2901264bda91045258b5d4120879ae292e950": "The SQuAD-style MRC task and report Extract Match (EM)",
    "23e16c1173b7def2c5cb56053b57047c9971e3bb": "Precision, Recall, and F1 scores on named entity and nominal mention are shown in a Chinese corpus that the word label \"End\" has a better performance than \"Begin\". This motivates us carry out a backward greedy search over each sentence's label sequence to identify word boundaries.",
    "23e2971c962bb6486bc0a66ff04242170dd22a1d": "Unanswerable",
    "2439b6b92d73f660fe6af8d24b7bbecf2b3a3d72": "They identify the correct candidate from the Wikipedia article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article article",
    "249c805ee6f2ebe4dbc972126b3d82fb09fa3556": "Unanswerable",
    "252a645af9876241fb166e5822992ce17fec6eb6": "38,182 videos",
    "25c1c4a91f5dedd4e06d14121af3b5921db125e9": "No",
    "26126068d72408555bcb52977cd669faf660bdf7": "For example, Mosquito and Gassin",
    "26327ccebc620a73ba37a95aabe968864e3392b2": "Unanswerable",
    "26c2e1eb12143d985e4fb50543cf0d1eb4395e67": "Unanswerable",
    "26e2d4d0e482e6963a76760323b8e1c26b6eee91": "462 speakers with 8 utterances each",
    "27275fe9f6a9004639f9ac33c3a5767fea388a98": "\n2",
    "2740e3d7d33173664c1c5ab292c7ec75ff6e0802": " MSA, MADAMIRA, RDI, Farasa, MIT, MADAMIRA, RDI, Farasa, MADAMIRA, RDI, Farasa, MADAMIRA",
    "277a7e916e65dfefd44d2d05774f95257ac946ae": "BiLSTM-CRF, BERT architecture for deriving text representations uses 12 hidden layers, consisting of 76 units each",
    "27cf16bc9ef71761b9df6217f00f39f21130ce15": "Yes",
    "27dbbd63c86d6ca82f251d4f2f030ed3e88f58fa": "An attention mechanism maps a query and a set of key-value pairs to an output",
    "27de1d499348e17fec324d0ef00361a490659988": "23,700 queries",
    "28067da818e3f61f8b5152c0d42a531bf0f987d4": "13 different hyperparameter settings of PARENT-C",
    "2858620e0498db2f2224bfbed5263432f0570832": "impact of various architectural choices.",
    "286078813136943dfafb5155ee15d2429e7601d9": "The baseline is much better for the KB. The baseline is much better for the KB.",
    "290ee79b5e3872e0496a6a0fc9b103ab7d8f6c30": "(1) we received annotations from individuals who were experienced in the platform",
    "2916bbdb95ef31ab26527ba67961cf5ec94d6afe": "53 documents, which contain an average number of 156 sentences per document, each with 19.55 tokens on average",
    "29923a824c98b3ba85ced964a0e6a2af35758abe": "Unanswerable",
    "29c014baf99fb9f40b5171aab3e2c7f12a748f79": "methods that provide improved accuracy",
    "29f2954098f055fb19d9502572f085862d75bf61": "a natural language input (e.g. \u201cI need a fast, family friendly, reliable car-speak)",
    "2a3e36c220e7b47c1b652511a4fdd7238a74a68f": "24 scientific articles collected from the ACM Digital Library (conference and workshop papers)",
    "2a564b092916f2fabbfe893cf13de169945ef2e1": "Twitter corpus, People sometimes prefer to spell English characters for the corresponding Turkish characters (e.g, c for the corpus) when writing in electronic format. To determine the corpus",
    "2a6003a74d051d0ebbe62e8883533a5f5e55078b": "CNN dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset dataset",
    "2ad4d3d222f5237ed97923640bc8e199409cbe52": "52.16% more accuracy than typing a full sentence in our user study.",
    "2b3cac7af10d358d4081083962d03ea2798cf622": "Yes",
    "2c59528b6bc5b5dc28a7b69b33594b274908cca6": "IMDB movie reviews BIBREF25 ,  BiLSTM ",
    "2c6b50877133a499502feb79a682f4023ddab63e": "WikiSmall and WikiLarge",
    "2c7494d47b2a69f182e83455fe4c75ae3b2893e9": "No",
    "2c78993524ca62bf1f525b60f2220a374d0e3535": "resources to use for each language is separate, a different and a large number of cluster labels (4, in the case of the text benchmark),  coordinate them with the weight of each subvector INLINEFORM5 , and also learning these weights using support vector machines (SVMs).",
    "2c7e94a65f5f532aa31d3e538dcab0468a43b264": "The dataset contains evaluating intent models and out-of-scope predictions based on topic areas found on Quora, Wikipedia, and elsewhere",
    "2c85865a65acd429508f50b5e4db9674813d67f2": "353 conversations between nurses and patients",
    "2c947447d81252397839d58c75ebcc71b34379b5": "CoinCollector games with the hardest setting used by BIBREF8, i.e. hard-level 30 (refer to the Appendix SECREF36 for more information) and use them as a benchmark",
    "2ccc26e11df4eb26fcccdd1f446dc749aff5d572": "Yes",
    "2cd37743bcc7ea3bd405ce6d91e79e5339d7642e": "Yes",
    "2ceced87af4c8fdebf2dc959aa700a5c95bd518f": "Yes",
    "2da4c3679111dd92a1d0869dae353ebe5989dfd2": "ESTER1, ETAPE, REPERE BIBREF16, ETAPE, REPERE BIBREF16, REPERE BIBREF16",
    "2dbf6fe095cd879a9bf40f110b7b72c8bdde9475": "ArXiv papers, U.S Senators from Alabama, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate ArXiv papers, U.S Senators from Alabama, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark",
    "2ddb51b03163d309434ee403fef42d6b9aecc458": "Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2ebedee",
    "2df4a045a9cd7b44874340b6fdf9308d3c55327a": "Dialog and e-commerce domain, we use the crowdsourcing labeled data",
    "2e37e681942e28b5b05639baaff4cd5129adb5fb": "Unanswerable",
    "2e89ebd2e4008c67bb2413699589ee55f59c4f36": " Siamese networks are available in eight datasets: 8,628",
    "2ea4347f1992b0b3958c4844681ff0fe4d0dd1dd": "NeuronBlocks",
    "2eb9280d72cde9de3aabbed993009a98a5fe0990": "110 scenarios, 128 questions with a learning rate of 15 questions per text",
    "2ee715c7c6289669f11a79743a6b2b696073805d": "Unanswerable",
    "2f901dab6b757e12763b23ae8b37ae2e517a2271": "German, English, English, German",
    "2fbb6322e485e7743ec3fb4bb02d44bf4b5ea8a6": "The two proposed models significantly outperforms the two baselines: The performance of the baselines is around .72 for $F_1$ , and the corresponding results for the combined AntSynNET model achieve an improvement of $>$$ $>$ $ $ .06.",
    "307e8ab37b67202fe22aedd9a98d9d06aaa169c5": "No",
    "30af1926559079f59b0df055da76a3a34df8336f": "Unanswerable",
    "30e21f5bc1d2f80f422c56d62abca9cd3f2cd4a1": "WikiQA, SQuAD, and InfoboxQA",
    "30eacb4595014c9c0e5ee9669103d003cfdfe1e5": " CNN",
    "31101dc9937f108e27e08a5f34be44f0090b8b6b": "Unanswerable",
    "3116453e35352a3a90ee5b12246dc7f2e60cfc59": "TF-IDF, LDA, LDA",
    "312e9cc11b9036a6324bdcb64eca6814053ffa17": "112 pathology reports",
    "31735ec3d83c40b79d11df5c34154849aeb3fb47": "Unanswerable",
    "31b92c03d5b9be96abcc1d588d10651703aff716": "90.325% (overfired)",
    "31d695ba855d821d3e5cdb7bea638c7dbb7c87c7": "chestra",
    "326588b1de9ba0fd049ab37c907e6e5413e14acd": "Simplicity BIBREF8, OpenNMT BIBREF24",
    "32a3c248b928d4066ce00bbb0053534ee62596e7": "CoNLL\u2013SIGMORPHON 2018 baseline system",
    "32d99dcd8d46e2cda04a9a9fa0e6693d2349a7a9": "The additive to previous context function of the embedding algorithm.",
    "3321d8d0e190d25958e5bfe0f3438b5c2ba80fd1": "2,936 consumer health questions classified using the GARD corpus of biomedical questions",
    "33554065284110859a8ea3ca7346474ab2cab100": "97.999% and 83.99% on average",
    "3355918bbdccac644afe441f085d0ffbbad565d7": "Unanswerable",
    "3415762847ed13acc3c90de60e3ef42612bc49af": "For text data augmentation, our approach improves over the base model by 3% and TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TREC, TC, TREC, TC, TC,TC, TC,T,TC,T,TT,TT,TT,TTT,TTTT,TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT",
    "348886b4762db063711ef8b7a10952375fbdcb57": "Yes",
    "34dc0838632d643f33c8dbfe7bd4b656586582a2": "The baseline model does not perform better in BLEU-1/4 than ROUGE ",
    "352bc6de5c5068c6c19062bad1b8f644919b1145": "120 audio files (60 speech and 60 music",
    "357eb9f0c07fa45e482d998a8268bd737beb827f": "KVMemnn, Feed Yourself, Poly-encoder, and a BERT bi-ranker baseline",
    "35b3ce3a7499070e9b280f52e2cb0c29b0745380": "Yes",
    "3611a72f754de1e256fbd25b012197e1c24e8470": "No",
    "36ae003c7cb2a1bbfa90b89c671bc286bd3b3dfd": "TV Tropes BIBREF3, a knowledge-based website dedicated to pop culture, containing information on a plethora of characters from a variety of sources",
    "375b281e7441547ba284068326dd834216e55c07": " co-reference resolutions, very less exploring topic, and answer can provide many more detailed responses",
    "37861be6aecd9242c4fdccdfcd06e48f3f1f8f81": "2017",
    "37a79be0148e1751ffb2daabe4c8ec6680036106": "Unanswerable",
    "37be0d479480211291e068d0d3823ad0c13321d3": "Translation accuracy is 86.66%.\nTranslation accuracy is 86.66",
    "37edc25e39515ffc2d92115d2fcd9e6ceb18898b": "The high-quality datasets the challenge organizers released.",
    "37f8c034a14c7b4d0ab2e0ed1b827cc0eaa71ac6": "BERT$ {}$baseitare, BIBREF24",
    "384bf1f55c34b36cb03f916f50bbefade6c86a75": "Unanswerable",
    "38e4aaeabf06a63a067b272f8950116733a7895c": "homographic scheme, homographic puns",
    "38f58f13c7f23442d5952c8caf126073a477bac0": "the score of the proposed model was 6.9 and 7.9 on SQuAD.\nThe scores of the models used in the experiments are trained with fasttext BIBREF18",
    "392fb87564c4f45d0d8d491a9bb217c4fce87f03": "RNN Model and AttentionRNN",
    "3941401a182a3d6234894a5c8a75d48c6116c45c": "24.3% (Accenture) and 30.27% (AUC) on average",
    "395b61d368e8766014aa960fde0192e4196bcb85": "FGM, FGVM, DeepFool, HotFlip, TYC and TYC",
    "3a6e843c6c81244c14730295cfb8b865cd7ede46": "SVM",
    "3b371ea554fa6639c76a364060258454e4b931d4": "we use the published news videos from NowThis Facebook page collected 0/2015 and 07/2016",
    "3b77b4defc8a139992bd0b07b5cf718382cb1a5f": "standardized industry taxonomies organize economic activities into groups based on similar production processes, products or services, delivery systems or behavior in financial markets",
    "3bf0306e9bd044f723e38170c13455877b2aeec3": "sensationalism reward isless more noisy, more fragile than the ROUGE-L reward or abstractive reward used in the summarization task",
    "3c3807f226ba72fc41f59f0338f12a49a0c35605": "Yes",
    "3c93894c4baf49deacc6ed2a14ef5e0f13b7d96f": "227 cities that have at least 100 bloggers",
    "3cd185b7adc835e1c4449eff81222f5fc15c8500": "We apply decision theory to enhancing the performance of our proposed features, we apply decision theory to enhancing the performance of our proposed features, we apply decision theory to enhancing the performance of our proposed features, we apply decision theory to enhancing the performance of our proposed features, we apply decision theory to enhancing the performance of our proposed features, we apply decision theory to enhancing the performance of our proposed features, and apply decision theory to enhancing the performance of our proposed features, we apply decision theory to enhancing the performance of our proposed features, and apply decision theory to enhancing the performance of our proposed features, and apply decision theory to enhancing the performance of our proposed features.",
    "3cf1edfa6d53a236cf4258afd87c87c0a477e243": "Unanswerable",
    "3d013f15796ae7fed5272183a166c45f16e24e39": "Parallel Wikipedia Simplification Corpus (PWKP)",
    "3d7a982c718ea6bc7e770d8c5da564fbb9d11951": "No",
    "3d7d865e905295d11f1e85af5fa89b210e3e9fdf": "11.73% more accuracy than typing a full sentence in our user study.",
    "3ddff6b707767c3dd54d7104fe88b628765cae58": "Plank et al. (2016) bi-LSTM-S",
    "3de0487276bb5961586acc6e9f82934ef8cb668c": "In a context where the most general information is taken into account whether a token is a defective to processed file or is manually annotated and replaced for the corpus to be shared, there is still much uncertainty regarding the pre-processing.",
    "3e1829e96c968cbd8ad8e9ce850e3a92a76b26e4": "32, 64, 64, 64",
    "3e432d71512ffbd790a482c716e7079ee78ce732": "MPCS, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML\n), MPCS, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML, AML , AML , AML , AML , AML , AML , AML , AML , AML , AML , AML , A MPCS, AML, AML, AML, AML, AML, AML, AML, AML, AML, A",
    "3e88fb3d28593309a307eb97e875575644a01463": "a neural sequential approach, and apply an ablation test to investigate their contribution",
    "3f0ae9b772eeddfbfd239b7e3196dc6dfa21365f": "Unanswerable",
    "3f856097be2246bde8244add838e83a2c793bd17": "elasticsearch",
    "3fad42be0fb2052bb404b989cc7d58b440cd23a0": "CodaLab ",
    "3fff37b9f68697d080dbd9d9008a63907137644e": "They obtained an overall f1-score of 82.9%",
    "40c0f97c3547232d6aa039fcb330f142668dea4b": "ArXiv papers, U.S Senators from Alabama, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate Yes",
    "41ac23e32bf208b69414f4b687c4f324c6132464": "English, German ",
    "41b2355766a4260f41b477419d44c3fd37f3547d": "Unanswerable",
    "41b70699514703820435b00efbc3aac4dd67560a": "751,555",
    "42084c41343e5a6ae58a22e5bfc5ce987b5173de": "No",
    "425bd2ccfd95ead91d8f2b1b1c8ab9fc3446cb82": "For each post we collected its title and the number of views of the corresponding video, which we consider our popularity metric.",
    "435570723b37ee1f5898c1a34ef86a0b2e8701bb": "Paraphrases are defined as a sequence of words that is a sequence of words that is a sequence of words that is a sequence of words that is a sequence of words that is a sequence of words that is a sequence of words which is a sequence of words which is a sequence of words which is a sequence of words which is a sequence of words which is a sequence of words which is a sequence of words which is a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence of words a sequence",
    "43eecc576348411b0634611c81589f618cd4fddf": "RL, RL, RL",
    "43f074bacabd0a355b4e0f91a1afd538c0a6244f": "Unanswerable",
    "440faf8d0af8291d324977ad0f68c8d661fe365e": "the BOW model",
    "443d2448136364235389039cbead07e80922ec5c": "Appraisal (PA) is a lively area of research where the most important question is asked.",
    "44497509fdf5e87cff05cdcbe254fbd288d857ad": "Unanswerable",
    "4477bb513d56e57732fba126944073d414d1f75f": "the authors thank Roy Robinson, Micro-F1 score of 82.17 and 2013 ShARe/CLEF Task 1",
    "455d4ef8611f62b1361be4f6387b222858bb5e56": "this dataset consists of complete dialogs containing questions requiring information whether dialog contains the answer, it can be answered without asking any additional information, they are still needed but they must provide a better one.",
    "45a5961a4e1d1c22874c4918e5c98bd3c0a670b3": "8K questions",
    "45be665a4504f0c7f458cf3f75a95d5a75eefd42": "Unanswerable",
    "45e9533586199bde19313cd43b3d0ecadcaf7a33": "Yes",
    "45f7c03a686b68179cadb1413c5f3c1d373328bd": "CORD-19 dataset",
    "46227b4265f1d300a5ed71bf40822829de662bc2": "CNN-Dailymail corpus",
    "4625cfba3083346a96e573af5464bc26c34ec943": "Unanswerable",
    "46c9e5f335b2927db995a55a18b7c7621fd3d051": "13 phenotypes were considered for annotation, and the label \u201cunsure\u201d was used to indicate that an operator would like to seek assistance determining the presence of an phenotype from a more senior physician.",
    "477d9d3376af4d938bb01280fe48d9ae7c9cf7f7": "Unanswerable",
    "48088a842f7a433d3290eb45eb0d4c6ab1d8f13c": "model is used to evaluate the baseline LSTM model",
    "483a699563efcb8804e1861b18809279f21c7610": "No",
    "48bd71477d5f89333fa7ce5c4556e4d950fb16ed": "ideal pronouns and indicative present verbs",
    "4907096cf16d506937e592c50ae63b642da49052": "10K tweets with cross-validated labels",
    "493e971ee3f57a821ef1f67ef3cd47ade154e7c4": "4 latent dimension values (K=25, 50, 75 and 100)",
    "4944cd597b836b62616a4e37c045ce48de8c82ca": "Phrase level opinion polarity from newswire BIBREF28",
    "49764eee7fb523a6a28375cc699f5e0220b81766": "Unanswerable",
    "4986f420884f917d1f60d3cea04dc8e64d3b5bf1": " multilingual model",
    "498c0229f831c82a5eb494cdb3547452112a66a0": "The best performers have average accuracy 0.71 for outcome datasets.",
    "49c32a2a64eb41381e5f12ccea4150cac9f3303d": "Bidirection, Length, Length, Length, Lines, and Lines, BIBREF1, BIBREF1, BIBREF1, BIBREF2",
    "49eb52b3ec0647e165a5e41488088c80a20cc78f": "contextual attraction, i.ratio INLINEFORM3 0.25%",
    "4a4ce942a7a6efd1fa1d6c91dedf7a89af64b729": "369,861 visual questions, 369,186 visual questions",
    "4aa9b60c0ccd379c6fb089c84a6c7b872ee9ec4f": "12,594 unique hashtags",
    "4ac2c3c259024d7cd8e449600b499f93332dab60": "Yes",
    "4bc2784be43d599000cb71d31928908250d4cef3": "Unanswerable",
    "4c07c33dfaf4f3e6db55e377da6fa69825d0ba15": "3,216",
    "4c18081ae3b676cc7831403d11bc070c10120f8e": " HR people, ADWS kernel, analytical skills, knowledge of the work done by, and the skills and expertise of the team can easily compare to a standard template of model goals",
    "4cbe5a36b492b99f9f9fea8081fe4ba10a7a0e94": "PDTB-style discourse relation parsing",
    "4d28c99750095763c81bcd5544491a0ba51d9070": "Unanswerable",
    "4d47bef19afd70c10bbceafd1846516546641a2f": "160K sentence pairs",
    "4d706ce5bde82caf40241f5b78338ea5ee5eb01e": "The English portion of the CoNLL 2003 dataset BIBREF200",
    "4d7ff4e5d06902de85b0e9a364dc455196d06a7d": "PPDB, Siamase CBOW, Skip-thought vectors BIBREF15 (STV)",
    "4dc268e3d482e504ca80d2ab514e68fd9b1c3af1": "48,705",
    "4dcf67b5e7bd1422e7e70c657f6eacccd8de06d3": "Unanswerable",
    "4e1a67f8dc68b55a5ce18e6cd385ae9ab90d891f": "Yes",
    "4e748cb2b5e74d905d9b24b53be6cfdf326e8054": "sarcasm detection",
    "4eaf9787f51cd7cdc45eb85cf223d752328c6ee4": "Wiktionary",
    "4ef11518b40cc55d86c485f14e24732123b0d907": "BERT, Human Evaluation, TYC, HotFlip",
    "4f253dfced6a749bf57a1b4984dc962ce9550184": "Unanswerable",
    "4fa6fbb9df1a4c32583d4ef70d2b29ece4b3d802": "two",
    "500a8ec1c56502529d6e59ba6424331f797f31f0": "10-fold cross-validation results of the two classifiers are provided in Table TABREF2 using the metrics of precision, recall, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure 10-fold cross-validation results of the two classifiers are provided in Table TABREF2 using the metrics of precision, recall, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Measure, F-Me-10.",
    "506d21501d54a12d0c9fd3dbbf19067802439a04": "Unanswerable",
    "509af1f11bd6f3db59284258e18fdfebe86cae47": "Unanswerable",
    "50be4a737dc0951b35d139f51075011095d77f2a": "GE-FL, Altendorf et al.text typed features which are highly predictive of single feature, LDA",
    "50cb50657572e315fd452a89f3e0be465094b66f": "Yes",
    "50cc6c5f2dcf5fb87b56007f6a825fa7c90b64ed": "The multilingual model uses word alignments in the EP data. Comparing with the existing dataset, German, to provide additional cross-validation for the target language",
    "50e80cfa84200717921840fddcf3b051a9216ad8": "Yes",
    "511517efc96edcd3e91e7783821c9d6d5a6562af": "Google Collections, Huggingface\u2019s Pytorch Transformer library (BIBREF23)",
    "5152b78f5dfee26f1b13f221c1405ffa9b9ba3a4": "Refresh against related extractive systems",
    "518dae6f936882152c162058895db4eca815e649": "Unanswerable",
    "51b1142c1d23420dbf6d49446730b0e82b32137c": "The baseline is the classification of the tweets in harassment and non-harassment tweets",
    "51fe4d44887c5cc5fc98b65ca4cb5876f0a56dad": "BERT-based baselines BIBREF51, BIBREF51, BIBREF34, BIBREF36",
    "521280a87c43fcdf9f577da235e7072a23f0673e": "Unanswerable",
    "5260cb56b7d127772425583c5c28958c37cb9bea": "Unanswerable",
    "52f8a3e3cd5d42126b5307adc740b71510a6bdf5": "For topic analyses, for the sentiment analysis task they used to evaluate the questions and the questions and the questions on the questions and the questions and the answers for the questions and the questions and the questions and the answers",
    "52f9cd05d8312ae3c7a43689804bac63f7cac34b": "Yes",
    "53014cfb506f6fffb22577bf580ae6f4d5317ce5": "CNN/DailyMail, NYT",
    "53aa07cc4cc4e7107789ae637dbda8c9f6c1e6aa": "104 telephone calls, 11 hours of audio with Spanish transcripts and their crowdsourcer",
    "53dfcd5d7d2a81855ec1728f0d8e6e24c5638f1e": "BERT, BiDAF, BERT",
    "545e92833b0ad4ba32eac5997edecf97a366a244": " segmentation of the sample snippets from 10 document classification datasets, covering the topic identification, coarse and normalized the mapping",
    "54830abe73fef4e629a36866ceeeca10214bd2c8": "ISWC and WWW, Topic model based on location recommendation systems: Recent research\nLDA algorithm using collapsed LDA sample",
    "54e945ea4b014e11ed4e1e61abc2aa9e68fea310": "English poem from an image, and Shakespeare plays as a  multimodal poem from an image, and Shakespeare plays as a  multimodal poem from an image, BIBREF1",
    "55139fcfe04ce90aad407e2e5a0067a45f31e07e": "Unanswerable",
    "551457ed34ca7fc0878c85bc664b135c21059b58": "RNNs, the gradients for each potential label can be obtained by back-propagation.",
    "5529f26f72ce47440c2a64248063a6d5892b9fde": "MT model with attention and attention mechanism on relevance",
    "55507f066073b29c1736b684c09c045064053ba9": "Arabic offensive language classifiers using state-of-of-the-art representations",
    "55569d0a4586d20c01268a80a7e31a17a18198e2": "Translation of Translation of Translation of Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Translation Transction translation Transction translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation translation",
    "559c68802ee2bb8b11e2188127418ca3a6155ba7": "Yes",
    "55bd59076a49b19d3283af41c5e3ccb875f3eb0c": "Unanswerable",
    "55c8f7acbfd4f5cde634aaecd775b3bb32e9ffa3": "high resource results for 85 languages",
    "565189b672efee01d22f4fc6b73cd5287b2ee72c": "the Europarl test NMT system",
    "567dc9bad8428ea9a2658c88203a0ed0f8da0dc3": "Unanswerable",
    "568fb7989a133564d84911e7cb58e4d8748243ef": "Go-Explore, DRQN++",
    "56a8826cbee49560592b2d4b47b18ada236a12b9": "Unanswerable",
    "56b034c303983b2e276ed6518d6b080f7b8abe6a": "K-means, AEM",
    "56b7319be68197727baa7d498fa38af0a8440fe4": "Unanswerable",
    "57f23dfc264feb62f45d9a9e24c60bd73d7fe563": "480-dimensional feature vector , 117.6%",
    "58355e2a782bf145b61ee2a3e0e426119985c179": "Data augmentation",
    "584af673429c7f8621c6bf83362a37048daa0e5d": "  we obtained the highest scores with the METEOR and BLEU-3 metrics",
    "585626d18a20d304ae7df228c2128da542d248ff": "Unanswerable",
    "58c6737070ef559e9220a8d08adc481fdcd53a24": "CCR, averaged for a set of tweets, is the number of incorrectly-predicted sentiments sent, and 8.1% of the negative sentiments. Labeling by 210.0",
    "58ee0cbf1d8e3711c617b1cd3d7aca8620e26187": "16,395 sentences from the training data split.",
    "58ef2442450c392bfc55c4dc35f216542f5f2dbb": "Yes",
    "5913930ce597513299e4b630df5e5153f3618038": "They improve interpretability compared to softmax",
    "596aede2b311deb8cb0a82d2e7de314ef6e83e4e": "10,000 sentences pairs annotated with the labels contradiction, eintail, and neutral",
    "59e58c6fc63cf5b54b632462465bfbd85b1bf3dd": "Egyptian, EGY, Gulf, Gulf, GA, Arabic, Gulf, GA, Arabic, Gulf, GA, Egyptian words, Gulf, Gulf, Gulf, Gulf, Gulf, Gulf, Gulf of U.Us, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, GA, G",
    "5a22293b055f5775081d6acdc0450f7bd5f5de04": "Randomly from the Table-CG\nGEM to determine the number of distinct records.",
    "5a65ad10ff954d0f27bb3ccd9027e3d8f7f6bb76": "NECKAr, EBP, EBP, EBP, EBP, EBP, EBP, EBP, EBP, EBP",
    "5a6926de13a8cc25ce687c22741ba97a6e63d4ee": "political news summaries in large datasets",
    "5a81732d52f64e81f1f83e8fd3514251227efbc7": "185, sans syntactic: 185, sans syntactic: 16,935, sans emotion: 16,946, sans emotion: 16,946, sans emotion: 16,954, sans emotion: 16,954",
    "5a8cc8f80509ea77d8213ed28c5ead501c68c725": "Unanswerable",
    "5aa12b4063d6182a71870c98e4e1815ff3dc8a72": "Yes",
    "5b551ba47d582f2e6467b1b91a8d4d6a30c343ec": "local coherence, predicting the likelihood that a recipe step follows the preceding, has the highest likelihood for the recipe conditioned on the first recipe,  we discard users with fewer than 4 reviews",
    "5b7a4994bfdbf8882f391adf1cd2218dbc2255a0": "Unanswerable",
    "5bb3c27606c59d73fd6944ba7382096de4fa58d8": "No",
    "5bc1dc6ebcb88fd0310b21d2a74939e35a4c1a11": "Unanswerable",
    "5c3e98e3cebaecd5d3e75ec2c9fc3dd267ac3c83": "the positive and negative polarity accuracy BIBREF15 network is widely used and is very efficient for irony detection",
    "5c5aeee83ea3b34f5936404f5855ccb9869356c1": "evaluation:\nPrevious work suggested: Testing:\nPrevious work:\nIn the following, in the following, in the in the in the in the in the in the in the in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in",
    "5c6fa86757410aee6f5a0762328637de03a569e9": "F1 score of 98.58",
    "5c88d601e8fca96bffebfa9ef22331ecf31c6d75": "Yes",
    "5cb610d3d5d7d447b4cd5736d6a7d8262140af58": "English test set to better understand the remaining shortcomings of the approach. ",
    "5cc2daca2a84ddccba9cdd9449e51bb3f64b3dde": "BIBREF7",
    "5da26954fbcd3cf6a7dba9f8b3c9a4b0391f67d4": "audio and textual inputs independently., We use the Google Cloud Speech API and retrieve the transcripts.",
    "5daeb8d4d6f3b8543ec6309a7a35523e160437eb": "German tweets labeled as non-aggressive, untargeted, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, unmarked, and unmarked tweeted.",
    "5e324846a99a5573cd2e843d1657e87f4eb22fa6": "bypasses the bottleneck by gathering occur of words related to the target word sense",
    "5eabfc6cc8aa8a99e6e42514ef9584569cb75dec": "Yes",
    "5eda469a8a77f028d0c5f1acd296111085614537": "French-English (Fr-En-Es), Romanian-English-French (De-En-Fr) and Romanian-English-German (Ro-En-De)",
    "5f60defb546f35d25a094ff34781cddd4119e400": "We use random search to the hyperparameter tuning of the LSTM language model, 223 pairs of words each.",
    "5fa36dc8f7c4e65acb962fc484989d20b8fdaeec": "Yes",
    "5fda8539a97828e188ba26aad5cda1b9dd642bc8": "Unanswerable",
    "600b097475b30480407ce1de81c28c54a0b3b2f8": "Unanswerable",
    "6024039bbd1118c5dab86c41cce1175d99f10a25": "parallel corpora of English-Japan and Japanese-English translation tasks using encode-decoder-reconstructor",
    "603fee7314fa65261812157ddfc2c544277fcf90": "2017",
    "60ce4868af45753c9e124e64e518c32376f12694": "The baseline is the baseline by the model used to extract the INLINEFORM0 initial candidates, we reimplementated the Word Breaker BIBREF16 as described in 1.1 billion English tweets from 1,268 manually segmented hashtags in the training set of STAN INLINEFORM2",
    "612c3675b6c55b60ae6d24265ed8e20f62cb117e": "Yes / rather no / no",
    "61652a3da85196564401d616d251084a25ab4596": "4528",
    "61a9ea36ddc37c60d1a51dabcfff9445a2225725": "news suggestion consensus\nestate section",
    "6236762b5631d9e395f81e1ebccc4bf3ab9b24ac": "Yes",
    "6263b2cba18207474786b303852d2f0d7068d4b6": "Unanswerable",
    "627b8d7b5b985394428c974aca5ba0c1bbbba377": "30m groups of 4 consecutive sentences",
    "62ea141d0fb342dfb97c69b49d1c978665b93b3c": "model shows that it isisher",
    "62f27fe08ddb67f16857fab2a8a721926ecbb6fb": "ironic style,  Semeval-2018 Task 3",
    "63488da6c7aff9e374561a24ba224e9ce7f65e40": "Unanswerable",
    "63a1cbe66fd58ff0ead895a8bac1198c38c008aa": "ShapeWorldICE",
    "63b92dcc701ec77fdb3355ede5d37d2fbf057bcc": "Google Colab with a single GPU using Python 3.6 and Tensorflow 2.0",
    "63bb2040fa107c5296351c2b5f0312336dad2863": "36 millions English tweets collected between August and September 2017",
    "63c3550c6fb42f41a0c93133e9fca12ac00df9b3": "Yes",
    "6415f38a06c2f99e8627e8ba6251aa4b364ade2d": "BIBREF16, BIBREF26, BIBREF26",
    "6424e442b34a576f904d9649d63acf1e4fdefdfc": "POS tagging and dependency grammar induction respectively",
    "642e8cf1d39faa1cd985d16750cdc6696c52db2f": "EN INLINEFORM0 RO, EN INLINEFORM0 RO",
    "64af7f5c109ed10eda4fb1b70ecda21e6d5b96c8": "Unanswerable",
    "6568a31241167f618ef5ede939053feaa2fb0d7e": "Yes",
    "660284b0a21fe3801e64dc9e0e51da5400223fe3": "Using the Spearman correlation as an example, the results were reported in BIBREF15 and WS-R using similar techniques.",
    "662870a90890c620a964720b2ca122a1139410ea": "Unanswerable",
    "664b3eadc12c8dde309e8bbd59e9af961a433cde": "No",
    "664db503509b8236bc4d3dc39cebb74498365750": "The BLEU score BIBREF34 aims at measuring to what extent the generated descriptions are literally closed to the ground truth, Qualitative improvement of the data-structure of the data-structure, the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the The BLEU score BIBREF34 aims at measuring to what extent the generated descriptions are close to the ground truth, Qualitative improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the data-structure, the improvement of the information-structure, the improvement of the information-",
    "66c96c297c2cffdf5013bab5e95b59101cb38655": "Unanswerable",
    "67b66fe67a3cb2ce043070513664203e564bdcbd": "2,250 contexts, 1,607 of which contain a pun",
    "67e9e147b2cab5ba43572ce8a17fc863690172f0": "By using level 3 workers on the Figure-Eight crowdsourcing platform for our experiments. The level of accuracy is 68% and 70% (AUC)",
    "67ec8ef85844e01746c13627090dc2706bb2a4f3": "Unanswerable",
    "682e26262abba473412f68cbeb5f69aa3b9968d7": "This dataset with annotation of type and target of offensive language",
    "6844683935d0d8f588fa06530f5068bf3e1ed0c0": "Unanswerable",
    "68df324e5fa697baed25c761d0be4c528f7f5cf7": "Unanswerable",
    "692c9c5d9ff9cd3e0ce8b5e4fa68dda9bd23dec1": "39 ",
    "6a14379fee26a39631aebd0e14511ce3756e42ad": "Unanswerable",
    "6a219d7c58451842aa5d6819a7cdf51c55e9fc0f": "Wiktionary, German, German, Mongolian and Chinese",
    "6a31db1aca57a818f36bba9002561724655372a7": "2,496",
    "6a633811019e9323dc8549ad540550d27aa6d972": "Yes",
    "6aa2a1e2e3666f2b2a1f282d4cbdd1ca325eb9de": "100000 different metrics",
    "6aaf12505add25dd133c7b0dafe8f4fe966d1f1d": "Penn Treebank, WikiText2, (WT-2) BIBREF20",
    "6b367775a081f4d2423dc756c9b65b6eef350345": "Yes",
    "6b53e1f46ae4ba9b75117fc6e593abded89366be": "Micro-averaged precision, recall and F-1 score",
    "6b6d498546f856ac20958f666fc3fd55811347e2": "BIBREF37",
    "6b7354d7d715bad83183296ce2f3ddf2357cb449": " system\nSLC task is binary, the FLC consists of 18 propaganda techniques BIBREF3. We concatenate features in the last hidden layer before classification",
    "6b9b9e5d154cb963f6d921093539490daa5ebbae": "SimLex BIBREF19 and Rare Word (RW) BIBREF20 word similarity datasets, Google Semantic (GSem) analogies BIBREF9, WC$, C$, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC,",
    "6bbbb9933aab97ce2342200447c6322527427061": "Unanswerable",
    "6becff2967fe7c5256fe0b00231765be5b9db9f1": "The movie movie, in which the task is to classify the movie reviews as positive or negtive, is used for testing the proposed methods",
    "6bf5620f295b5243230bc97b340fae6e92304595": "BIBREF3, BIBREF3",
    "6bf93968110c6e3e3640360440607744007a5228": "Unanswerable",
    "6bfba3ddca5101ed15256fca75fcdc95a53cece7": "18 propaganda techniques",
    "6c91d44d5334a4ac80100eead4e105d34e99a284": "Deletion, DD, Cai, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, LKN, L",
    "6c96e910bd98c9fd58ba2050f99b9c9bac69840a": "2014 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIBREF7 BIB",
    "6ca938324dc7e1742a840d0a54dc13cc207394a1": "160K sentence pairs",
    "6cd25c637c6b772ce29e8ee81571e8694549c5ab": "WikiBio dataset ",
    "6cd8bad8a031ce6d802ded90f9754088e0c8d653": "Their results in Table TABREF14",
    "6d1217b3d9cfb04be7fcd2238666fa02855ce9c5": "BiLSTM+CNN(grapheme-level embeddings)",
    "6d4400f45bd97b812e946b8a682b018826e841f1": "methods: (i) linguistic bias, (ii) linguistic bias, and (ii) misleading.",
    "6ecb69360449bb9915ac73c0a816c8ac479cbbfc": "Support for conversational questions, e.g., BIBREF13, BIBREF14, BIBREF15, and joint search and recommendation, e.g., BIBREF16, BIBREF17, in the future.",
    "7006c66a15477b917656f435d66f63760d33a304": "163.6% and 13.8%",
    "70148c8d0f345ea36200d5ba19d021924d98e759": "Unanswerable",
    "701571680724c05ca70c11bc267fb1160ea1460a": "Yes",
    "709feae853ec0362d4e883db8af41620da0677fe": "Unanswerable",
    "70a1b0f9f26f1b82c14783f1b76dfb5400444aa4": "1-gram model, 1-word phrase\nJVnSegmenter, EVBCor%)",
    "70e9210fe64f8d71334e5107732d764332a81cb1": "WSJ, Librispeech",
    "71a0c4f19be4ce1b1bae58a6e8f2a586e125d074": "Unanswerable",
    "71b1af123fe292fd9950b8439db834212f0b0e32": "The goal of multisimethodims is to find direct or approximate translations for the 1,888 two languages",
    "71ba1b09bb03f5977d790d91702481cc406b3767": "Majority Class, Majority Class, Multilingual Berteline, Multilingual Berteline",
    "71bd5db79635d48a0730163a9f2e8ef19a86cd66": "the number of words jointly occurring occurr in a question, a level of leisure, where the answer is a continuous span taken from the passage, Paraphrase, where the answer is a parap span taken from the passage, Paraphrase, where the answer is a parap span taken from the passage, Paraphrase, where the answer is a parap span taken from the passage, Paraphrase, where the answer is a parap span taken from the text span",
    "71e4ba4e87e6596aeca187127c0d088df6570c57": "For expert question and professional question answering service, use the Flickr30K Entities BIBREF8 questions and answers editorial team on an informatically interesting question and professional question. Flickr30K Entities BIBREF8 questions and answers editorial team on an informatically interesting question and professional question",
    "71fe5822d9fccb1cb391c11283b223dc8aa1640c": "a hierarchical structure that includes all the terms of the chankees' realm and a hierarchical structure that includes all the terms of the chankees' realm and a hierarchical structure that includes all the terms of the chankees' realm and a hierarchical structure that includes all the terms of the chankees' realm and a hierarchical structure including all the terms of chankees' realm and a hierarchical structure including all the terms of chankees' realm and a hierarchical structure including all the terms of chankees' realm and a hierarchical structure including all the terms of chankees' realm and a hierarchical structure including all the terms of chan. The core that includes all the terms of chankees' realm and a hierarchical structure including all of the terms of chankees' realm",
    "72755c2d79210857cfff60bfbcb55f83c71ada51": "Unanswerable",
    "729694a9fe1e05d329b7a4078a596fe606bc5a95": "Unanswerable",
    "72ce05546c81ada05885026470f4c8c218805055": "Unanswerable",
    "72e4e26d0dd79c590c28b10938952a9f9497ff1e": "a collection of line-by-line modern paraphrases for 16, 172, 256",
    "72ed5fed07ace5e3ffe9de6c313625705bc8f0c7": "Unanswerable",
    "72f7ef55e150e16dcf97fe443aff9971a32414ef": "STERA",
    "73906462bd3415f23d6378590a5ba28709b17605": "a subset of 5 websites that represent a diverse set of genres: a newspaper, an economy forum, a celebrity magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, a consumer magazine, and a consumer magazine a consumer, and the consumer newsletter, and the consumer's own website",
    "73a7acf33b26f5e9475ee975ba00d14fd06f170f": "353 conversations between nurses and patients",
    "73bddaaf601a4f944a3182ca0f4de85a19cdc1d2": "Daily Mail news articles released by BIBREF9",
    "73e83c54251f6a07744413ac8b8bed6480b2294f": "Unanswerable",
    "7438b6b146e41c08cf8f4c5e1d130c3b4cfc6d93": "Yes",
    "747b847d687f703cc20a87877c5b138f26ff137d": "BIBREF3, BIBREF5, EN-DE section of the Europarl corpus BIBREF13",
    "74b338d5352fe1a6fd592e38269a4c81fe79b866": "Unanswerable",
    "74b4779de437c697fe702e51f23e2b0538b0f631": "their average accuracy on the noun phrase and the noun phrase similarity score",
    "74e866137b3452ec50fb6feaf5753c8637459e62": "elasticsearch",
    "74fb77a624ea9f1821f58935a52cca3086bb0981": "100 annotators",
    "7561a968470a8936d10e1ba722d2f38b5a9a4d38": "504white, 66 asian, and 36 black babies",
    "7595260c5747aede0b32b7414e13899869209506": "\n 15MB, 800 games",
    "75df70ce7aa714ec4c6456d0c51f82a16227f2cb": "7] - 7 - 7\n- 7 - 7\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  - -  -  -  -    -                                                                                                  ",
    "75ff6e425ce304a35f18c0230c0d13d3913a31a9": "Yes",
    "76121e359dfe3f16c2a352bd35f28005f2a40da3": "Unanswerable",
    "761de1610e934189850e8fda707dc5239dd58092": "RNMT, Transformer models (b3) , Transformer models (b3) , Transformer models (b3) , Transformer models (b3)",
    "7697baf8d8d582c1f664a614f6332121061f87db": "RST Treebank, N-grams, RST Treebank, N-grams, POS, Dialogical models",
    "76ed74788e3eb3321e646c48ae8bf6cdfe46dca1": "Arabic nouns, adjectives, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pronouns, pron the character-level and word-level bidirectional Long-Short Term Memory (biLSTM) based recurrent neural models for CW dia",
    "7705dd04acedaefee30d8b2c9978537afb2040dc": "character-level model achieves SQ accuracies of 70.9% and 70.3% on the FB2M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and FB5M and",
    "777217e025132ddc173cf33747ee590628a8f62f": "ArXiv papers, U.S Senators from Alabama, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate a set of datasets: ArXiv papers, U.S Senators from Alabama, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,",
    "777bb3dcdbc32e925df0f7ec3adb96f15dd3dc47": "Unanswerable",
    "7784d321ccc64db5141113b6783e4ba92fdd4b20": "RNNGs with induced trees, we use the parameterization and hyperparameters from BIBREF17 , RNNGs",
    "7793805982354947ea9fc742411bec314a6998f6": "Yes",
    "77c34f1033702278f7f044806c1eba0c6ecb8b04": "Unanswerable",
    "78292bc57ee68fdb93ed45430d80acca25a9e916": "Unanswerable",
    "784ce5a983c5f2cc95a2c60ce66f2a8a50f3636f": "Yes",
    "78536da059b884d6ad04680baeb894895458055c": "Our experimentation, shown the usefulness of transformer-based architectures in the field of negation detection and scope resolution",
    "787c4d4628eac00dbceb1c96020bff0090edca46": "a multi-target stance dataset which provides two targets per instance",
    "78a4ec72d76f0a736a4a01369a42b092922203b6": "Twitter dataset, 8 basic emotions from emotion",
    "78a5546e87d4d88e3d9638a0a8cd0b7debf1f09d": "CLA, natural language interface to structured and semi-structured data",
    "792f6d76d2befba2af07198584aac1b189583ae4": "Yes",
    "79413ff5d98957c31866f22179283902650b5bb6": "e.g., Kendall's Tau rank correlation BIBREF19 as suggested by BIBREF20 for automatic evaluation of information.",
    "79a44a68bb57b375d8a57a0a7f522d33476d9f33": "BLEU score, Rotowire dataset",
    "79f9468e011670993fd162543d1a4b3dd811ac5d": "1.5% ROI on RL, 2.5% ROI on RL, 3% ROI on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL, 3% on RL,",
    "7ab9c0b4ceca1c142ff068f85015a249b14282d0": "Yes",
    "7ae38f51243cb80b16a1df14872b72a1f8a2048f": "demonstrate that the combined network improves the classification accuracy by a mean margin of 22.2%",
    "7b4992e2d26577246a16ac0d1efc995ab4695d24": "The baseline used for generating all types of errors.",
    "7b4fb6da74e6bd1baea556788a02969134cf0800": "Yes",
    "7b9ca0e67e394f1674f0bcf1c53dfc2d474f8613": "English INLINEFORM0 German and English INLINEFORM1 French",
    "7bd6a6ec230e1efb27d691762cc0674237dc7967": "Penn Treebank, WikiText2, (WT-2) BIBREF20",
    "7cd22ca9e107d2b13a7cc94252aaa9007976b338": "No",
    "7d2f812cb345bb3ab91eb8cbbdeefd4b58f65569": "two pair of ERP components from BIBREF0 can be predicted above chance by a model which has been pretrained using a language modeling objective and then directly trained to predict the components",
    "7d483077ed7f2f504d59f4fc2f162741fa5ac23b": "ArXiv papers, U.S Senators from Alabama, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate, Republicans from Ark,Senate ArXiv papers, U.S Senators from Alabama, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark, Republicans from Ark,Senate from Ark",
    "7e38e0279a620d3df05ab9b5e2795044f18d4471": "Twitter",
    "7e4ef0a4debc048b244b61b4f7dc2518b5b466c0": "Document-level NMT, document-level Transformer, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document-level Machine translation, Document",
    "7e62a53823aba08bc26b2812db016f5ce6159565": "IITB English, ILCI (Bi-LSTM)",
    "7ee5c45b127fb284a4a9e72bb9b980a602f7445a": "Answer with content missing: (Table 2) The baselines are: (a) trained on S-SQuAD, (b) trained on T-S-S, (c) trained on T-S-S, and then fine-tuned on S-S.",
    "7f207549c75f5c4388efc15ed28822672b845663": "Unanswerable",
    "7fa3c2c0cf7f559d43e84076a9113a390c5ba03a": "Yes",
    "7fb27d8d5a8bb351f97236a1f6dcd8b2613b16f1": "Google Colab's TPU v2 with a batch size of 16, a learning rate of $2 \\cdot 10{4}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$}$quipment was thatLED by Google.",
    "8060a773f6a136944f7b59758d08cc6f2a59693b": "17000 hours of Shenma voice search",
    "808f0ad46ca4eb4ea5492f9e14ca043fe1e206cc": "1048 more closely the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the",
    "81588e0e207303c2867c896f3911a54a1ef7c874": "Through experiments using descriptive language models to assess the learning performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance performance",
    "81a35b9572c9d574a30cc2164f47750716157fc8": "Unanswerable",
    "81d193672090295e687bc4f4ac1b7a9c76ea35df": "GENERAL, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBAK, TANBA, TANBAKT, TANBA, TANBAKT, TANBA, TANBATBA, TANBATBA, TANBATBA, TANBATBA, TANBATBA, TANBATBA, TANBATBA, TANBATBA, TANBATBA, TANTBATBA, TANTBATBA, TANTBATBA, TANTTETETETETETETETETETETETETETETETETETETETETETE",
    "81d607fc206198162faa54a796717c2805282d9b": "1750 questions more than the list of questions",
    "81dbe9a9ddaa5d02b02e01a306d898015a56ffb6": "PPA, cross-entropy, baselines",
    "82595ca5d11e541ed0c3353b41e8698af40a479b": "the number of followers of all the handles in set$P$ could increase significantly.",
    "82642d3111287abf736b781043d49536fe48c350": "The dataset contains annotated. Each tweets is annotated as no evidence of depression (e.g., \u201cCitizens fear an economic depression)",
    "84bad9a821917cb96584cf5383c6d2a035358d7c": "using commonsense knowledge about everyday activities, 80 of them and decide to formulate a plausible correct and a plausible incorrect answer candidate to answerable questions (text-based or script-based)",
    "85590bb26fed01a802241bc537d85ba5ef1c6dc2": " annotation phenomena clusters",
    "861187338c5ad445b9acddba8f2c7688785667b1": "No",
    "867290103f762e1ddfa6f2ea30dd0a327f595182": "RNNGs with induced trees, we use the parameterization and hyperparameters from BIBREF17 , RNNGs",
    "869feb7f47606105005efdb6bea1c549824baea0": "492",
    "86bf75245358f17e35fc133e46a92439ac86d472": "The English portion of the CoNLL 2000 dataset BIBREF20 is considered to maximize the likelihood of each word $x_i$ given the words that precede it, $p(x_i$ \\mid x_{ x_{<i}$ Given a corpus that is annotated with shallow syntax, we propose to condition on both the preceding words and their annotations.)",
    "8748e8f64af57560d124c7b518b853bf2711c13e": "Yes",
    "8756b7b9ff5e87e4efdf6c2f73a0512f05b5ae3f": "No",
    "876700622bd6811d903e65314ac75971bbe23dcc": "Twitter for instance, the different settings of classification are related to tweets",
    "87bb3105e03ed6ac5abfde0a7ca9b8de8985663c": "monolingual data into NMT ",
    "87bc6f83f7f90df3c6c37659139b92657c3f7a38": "By using the parallel Hindi sentences from IIIT-Hyderabad BIBREF3 to ",
    "887c6727e9f25ade61b4853a869fe712fe0b703d": "Unanswerable",
    "88ab7811662157680144ed3fdd00939e36552672": "Text-adventure games, require the generation of actions consisting of up to five-words from a relatively modest vocabulary of 697 words recognized by the game's parser",
    "88bf368491f9613767f696f84b4bb1f5a7d7cb48": "Yes",
    "88e5d37617e14d6976cc602a168332fc23644f19": "WikiConv dataset",
    "88e62ea7a4d1d2921624b8480b5c6b50cfa5ad42": "101 clinical terms pairs whose semantic similarity is measured using different terms",
    "8910ee2236a497c92324bbbc77c596dba39efe46": "score of 8544 movie reviews, with a vocabulary of over 78K words,",
    "891c2001d6baaaf0da4e65b647402acac621a7d2": "By using  coordinates.62.51 and 12.42 of of of the variance in a word's contextualized representations to be explained by a static embedding.",
    "893ec40b678a72760b6802f6abf73b8f487ae639": "The model can identify, estimate, report or report on tweets that contain syntactical and contextual information extracted from BERT' syntactical and contextual information extracted from BERT' syntactical and contextual information extracted from BERT' syntactical and contextual information extracted from BERT' syntactical and contextual information extracted from BERT' syntactical and contextual information extracted from BERT' syntactical and contextual information extracted from BERT' syntactical and contextual information extracted from BERT' syntactical and contextual information extracted from BERT' syntactical and contextually context",
    "89497e93980ab6d8c34a6d95ebf8c1e1d98ba43f": "experts",
    "897ba53ef44f658c128125edd26abf605060fb13": "Yes",
    "899ed05c460bf2aa0aa65101cad1986d4f622652": "1. There are 16 languages that are used as mandatory language attributes.",
    "8a1c0ef69b6022a0642ca131a8eacb5c97016640": "context are tweets",
    "8a7615fc6ff1de287d36ab21bf2c6a3b2914f73d": "CoNLL-2003 IOB format25, BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLST-CNN-CRF BiLST-C-CRF BiLST-C-CG-CG-CG-CG-CG-CG CoNLL-2003 IOB format25, BiLSTM-CNN-CRF BiLST-CNN-CRF BiLST-C-CG-CG-CG-CG-CG-CG-CG-CG-CG-CG-CG-CG-CG-CG-CG-CG",
    "8acab64ba72831633e8cc174d5469afecccf3ae9": "Unanswerable",
    "8b0abc1907c2bf3e0256f8cf85e0ba66a839bd92": "Yes",
    "8b3d3953454c88bde88181897a7a2c0c8dd87e23": "Spearman's Rank Correlation ( INLINEFORM0 )",
    "8b9c12df9f89040f1485b3847a29f11b5c9262e0": "No",
    "8bb0011ad1d63996d5650770f3be18abdd9f7fc6": "Yes",
    "8bf7f1f93d0a2816234d36395ab40c481be9a0e0": "Yes",
    "8c48c726bb17a17d70ab29db4d65a93030dd5382": "100k documents",
    "8c852fc29bda014d28c3ee5b5a7e449ab9152d35": "linear SVM trained on word unigrams",
    "8ce11515634236165cdb06ba80b9a36a8b9099a2": "No",
    "8d074aabf4f51c8455618c5bf7689d3f62c4da1d": "Unanswerable",
    "8d4ac4afbf5b14f412171729ceb5e822afcfa3f4": "Yes",
    "8db6f8714bda7f3781b4fbde5ebb3794f2a60cfe": "Unanswerable",
    "8dc707a0daf7bff61a97d9d854283e65c0c85064": "Yes",
    "8dd8e5599fc56562f2acbc16dd8544689cddd938": "They define a context of each word.",
    "8dda1ef371933811e2a25a286529c31623cca0c6": "\n 1000 Arabic tweets with 30-dimensional vectors",
    "8de9f14c7c4f37ab103bc8a639d6d80ade1bc27b": "accuracy",
    "8df35c24af9efc3348d3b8d746df116480dfe661": "Yes",
    "8e12b5c459fa963b3e549deadb864c244879fe82": "4 layers",
    "8e44c02c2d9fa56fb74ace35ee70a5add50b52ae": "Yes",
    "8e52637026bee9061f9558178eaec08279bf7ac6": "Unanswerable",
    "8eefa116e3c3d3db751423cc4095d1c4153d3a5f": "Deeplearning4j framework",
    "8f16dc7d7be0d284069841e456ebb2c69575b32b": "                                                                                                                                                                                                      ",
    "902b3123aec0f3a39319ffa9d05ab8e08a2eb567": "Unanswerable",
    "907b3af3cfaf68fe188de9467ed1260e52ec6cf1": "1) spread tweets containing fake news and viral tweets containing not containing fake news",
    "90d946ccc3abf494890e147dd85bd489b8f3f0e8": "perplexity,  CDA",
    "9122de265577e8f6b5160cd7d28be9e22da752b2": "",
    "9132d56e26844dc13b3355448d0f14b95bd2178a": "18 fine-grained NER labels in the dataset",
    "9176d2ba1c638cdec334971c4c7f1bb959495a8e": "Unanswerable",
    "9193006f359c53eb937deff1248ee3317978e576": "BBCSport, BBCSport, BBCSport, BBCSport, BBCSport, BBCSport, BBCSport, BBCSport",
    "91e326fde8b0a538bc34d419541b5990d8aae14b": "WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, WMT15 German-English dataset, W",
    "9225b651e0fed28d4b6261a9f6b443b52597e401": "explanation for the results explanation for the results: (ii) that it uses \u201cfine-tuning\u201d: upon convergence of the baseline model, we resume training with a 2M sentence in-domain corpus mixed with an equal amount of randomly selected out-of-domain natural sentences",
    "92294820ac0d9421f086139e816354970f066d8a": "1.86 v.s. 2.87",
    "92bb41cf7bd1f7886784796a8220ed5aa07bc49b": "BERT, Human Evaluation, TYC, HotFlip",
    "92d1a6df3041667dc662376938bc65527a5a1c3c": "Yes",
    "92dfacbbfa732ecea006e251be415a6f89fb4ec6": "South African languages still under resourced from the point of view of building data driven by by by by by by by by by by by by by by by NCHLT text corpora BIBREF17, The WiLI-2018 benchmark dataset BIBREF4444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444444",
    "932b39fd6c47c6a880621a62e6a978491d881d60": "WN18, the average accuracy of all parameters, weighted by the hyperparameter $\\eta $ , We construct negative triplets following the same setting used in BIBREF3 .",
    "935d6a6187e6a0c9c0da8e53a42697f853f5c248": "over 20,000 blog users, 560K blog posts, and 560K blog posts",
    "93beae291b455e5d3ecea6ac73b83632a3ae7ec7": "By using the lowest value of all three languages, MT and Constraint Decoder (2018) to measure the word importance, which is significantly higher than the summing of the number of words",
    "955cbea7e5ead36fb89cd6229a97ccb3febcf8bc": " we used humorous and non-humorous.",
    "955de9f7412ba98a0c91998919fa048d339b1d48": "Support Vector Machine with linear kernel",
    "9658b5ffb5c56e5a48a3fea0342ad8fc99741908": "No",
    "968b7c3553a668ba88da105eff067d57f393c63f": "1) spread tweets containing fake news and viral tweets containing not containing fake news",
    "96a4091f681872e6d98d0efee777d9e820cb8dae": "Unanswerable",
    "96b07373756d7854bccc3c12e8d41454ab8741f5": "Yes",
    "97466a37525536086ed5d6e5ed143df085682318": "DUC and TAC208, Open Information Extraction approach",
    "975e60535724f4149c7488699a199ba2920a062c": "ally Unanswerable",
    "97d0f9a1540a48e0b4d30d7084a8c524dd09a4c3": "we compare our approach (FacTweet) to the following set of baselines: Twitter, suspicious Twitter, chatter-dance, follow-through, follow-through, follow-through, follow-through, and follow-through.",
    "97d1ac71eed13d4f51f29aac0e1a554007907df8": "Unanswerable",
    "981fd79dd69581659cb1d4e2b29178e82681eb4d": "the proposed models achieve the better performance regarding both evaluation metrics across all domains in all test cases, the proposed models consistently achieve the better performance regarding both evaluation metrics across all datasets in all test cases, and RALSTM",
    "984fc3e726848f8f13dfe72b89e3770d00c3a1af": "entity-document and temporal features",
    "99e78c390932594bd833be0f5c890af5c605d808": " pathology information extraction, 3) attention and 3) information about a concept/condition/condition/entity can change the rating on a clinical summarization task",
    "9a05a5f4351db75da371f7ac12eb0b03607c4b87": "Transformer-big Model with 1024 embedding/hidden units",
    "9a7ba5ed1779c664d2cac92494a43517d3e87c96": "Unanswerable",
    "9a8b9ea3176d30da2453cac6e9347737c729a538": "Fever, head, neck andache",
    "9a9d225f9ac35ed35ea02f554f6056af3b42471d": "1) the corrected version of the same FCE training set on which the system is trained (450K tokens), and 2) example sentences extracted from the English Vocabulary Profile (270K tokens)",
    "9af3142630b350c93875441e1e1767312df76d17": "Yes",
    "9b4dc790e4ff49562992aae4fad3a38621fadd8b": "Support Vector Regression (SVR) for regression problems",
    "9b7655d39c7a19a23eb8944568eb5618042b9026": "1,000 randomly selected tweets contains more than twice as many tweets about Trump than about the other candidates",
    "9b76f428b7c8c9fc930aa88ee585a03478bff9b3": "10 documents",
    "9b97805a0c093df405391a85e4d3ab447671c86a": "F1 score, W-GAN",
    "9bb7ae50bff91571a945c1af025ed2e67714a788": "PPA, cross-entropy, baselines",
    "9bd080bb2a089410fd7ace82e91711136116af6c": "For CNN, we used BERT, ELMo and FLAIR",
    "9bfebf8e5bc0bacf0af96a9a951eb7b96b359faa": "180K+ recipe texts and 700K+ reviews",
    "9c33b340aefbc1f15b6eb6fb3e23ee615ce5b570": "EEG data is high dimensional multivariate time series data whose dimensionality depends on the number of electrodes, it is notable that the combined network architecture composed of three supervised and a single unsupervised learning step, discussed in the next subsections and shown in Fig. FIGREF14 .",
    "9c44df7503720709eac933a15569e5761b378046": "English",
    "9ca447c8959a693a3f7bdd0a2c516f4b86f95718": "Galatasaray (namely Target-1) and Felipe (Mu)",
    "9cf070d6671ee4a6353f79a165aa648309e01295": "30, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40",
    "9da1e124d28b488b0d94998d32aa2fa8a5ebec51": "Kanban, Peng, Peng, Peng, Peng, Peng, Peng, Peng, Peng, Pioneppe",
    "9de2f73a3db0c695e5e0f5a3d791fdc370b1df6e": "No",
    "9eabb54c2408dac24f00f92cf1061258c7ea2e1a": "Parallel Wikipedia Simplification Corpus (PWKP)",
    "9ec1f88ceec84a10dc070ba70e90a792fba8ce71": "ppets 90.325%",
    "9ecde59ffab3c57ec54591c3c7826a9188b2b270": "the number of words jointly occurring occurring in a question, the number of sentences",
    "9ee07edc371e014df686ced4fb0c3a7b9ce3d5dc": "Freebase2M, SimpleQuestions, WebQSP, AMPCNN",
    "a0543b4afda15ea47c1e623c7f00d4aaca045be0": "No",
    "a103636c8d1dbfa53341133aeb751ffec269415c": "RNN outperforms both baselines in all four datasets (Amazon reviews BIBREF23 , BIBREF24 )",
    "a130306c6662ff489df13fb3f8faa7cba8c52a21": "Dropout's relative to the LSTM's fed-forward and backward pass-forward on a single batch during training of the RNN LM on PTB",
    "a15bc19674d48cd9919ad1cf152bf49c88f4417d": "The system uses a written RNN encoder, followed by a fully-connect layer and an RNN decoder. An RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, an RNN decoder, RNN decoder and RNN decoder.",
    "a1645d0ba50e4c29f0feb806521093e7b1459081": "Overall, our best F1 score of 2223 is 552.95.\nOverall, our best F1 score of 223 is 552.95.\nOverall, our best F1 score of 223 is 552.95.\nOverall, our best F1 score of 223 is 552.95.\nOverall, our best F1 score of 223 is 552.95.\nOverall, our best F1 score of 223 is 552.95.",
    "a1ac2a152710335519c9a907eec60d9f468b19db": "Unanswerable",
    "a1b3e2107302c5a993baafbe177684ae88d6f505": "30 different filters of sizes 3, 4 and 5, The embeddings of each character or grapheme involving the child are also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also also",
    "a1dac888f63c9efaf159d9bdfde7c938636f07b1": "Support Vector Regression (SVR) for regression problems",
    "a2015f02dfb376bf9b218d1c897018f4e70424d7": "45,000 scholar articles, 590000 sentences",
    "a253749e3b4c4f340778235f640ce694642a4555": "Gender representation is measured in terms number of speakers, number of utterances",
    "a267d620af319b48e56c191aa4c433ea3870f6fb": "Table TABREF10 contains excerpts from reviews with the car-speak terms bolded.",
    "a29c071065d26e5ee3c3bcd877e7f215c59d1d33": "Phrase level opinion polarity from newswire BIBREF29",
    "a313e98994fc039a82aa2447c411dda92c65a470": "Unanswerable",
    "a32c792a0cef03218bf66322245677fc2d5e5a31": "They use publicly available software and online demo of our results ",
    "a3bb9a936f61bafb509fa12ac0a61f91abcc5106": "2,937 consumer health questions questions classified using the BERT-Large model",
    "a3d9b101765048f4b61cbd3eaa2439582ebb5c77": "Translation accuracy is 86.02\nTranslation accuracy is 80.02\nTranslation accuracy is 80.02",
    "a3efe43a72b76b8f5e5111b54393d00e6a5c97ab": "0.858",
    "a4a1fcef760b133e9aa876ac28145ad98a609927": "36 millions English tweets collected between August and September 2017",
    "a4d115220438c0ded06a91ad62337061389a6747": "types of questions, their use in sentiment analysis for extracting the causes of crime, RNN-based model for its structural effectiveness in this task (see details in section UID13 ).",
    "a5505e25ee9ae84090e1442034ddbb3cedabcf04": "16,000 tweets (80%/20% train/test split.) Each record includes the raw tweet text (including accents and emoticons), a binary humor label, the number of votes for each of five star ratings and a \"Funniness Score\" that is the average of the 1 to 5 star cast.",
    "a5e49cdb91d9fd0ca625cc1ede236d3d4672403c": "EM, SAN",
    "a5e5cda1f6195ab1336855f1e39a609d61326d62": "Semantic Web Web (2019) Semantic Web (2019)",
    "a616a3f0d244368ec588f04dfbc37d77fda01b4c": "Unanswerable",
    "a66a275a817f980c36e0b67d2e00bd823f63abf8": "They use publicly available software and online demo of our results ",
    "a69a59b6c0ab27bcee1a780d6867df21e30aec08": "Yes",
    "a6a48de63c1928238b37c2a01c924b852fe752f8": "Lead-3 model",
    "a6d37b5975050da0b1959232ae756fc09e5f87e8": "2013",
    "a6d3e57de796172c236e33a6ceb4cca793dc2315": "Refresh as a shorthand for REINFORCE",
    "a712718e6596ba946f29a99838d82f95b9ebb1ce": "37,500 training samples with 75 abbreviation terms, 50 sentences",
    "a74190189a6ced2a2d5b781e445e36f4e527e82a": "merit and due to the model 'hack'\n merit and due to the model 'hack' for cyberattack, for political purposes, we use level 3 workers on the Figure-Eight crowdsourcing platform for our experiments, level 3 workers on the Figure-Eight crowdsourcing platform for our experiments",
    "a778b8204a415b295f73b93623d09599f242f202": "Random Forest, Decision Tree (DT), Naive Bayes (NB), Support vector machine (SVM) linear and RBF kernels, Logistic Regression, and Random kitchen sinks",
    "a7d020120a45c39bee624f65443e09b895c10533": "in relation to chat, in relation to discussions, where the goal is to formulate a strategy that \u201cgets the inference task feasible.\u201d. Considering PR methods, inference is possible, if (1) INLINEFORM0 becomes known to its KB, (inquirements)",
    "a87a009c242d57c51fc94fe312af5e02070f898b": " we model operationalize key domain-independent aspects of psychology.",
    "a8f51b4e334a917702422782329d97304a2fe139": "1) spread tweets containing fake news and viral tweets containing not containing fake news",
    "a9337636b52de375c852682a2561af2c1db5ec63": "Yes",
    "a99fdd34422f4231442c220c97eafc26c76508dd": "No",
    "a9a532399237b514c1227f2d6be8601474e669be": "MIMIC-III (NOTEEVENTS table ) and Case Reports articles from PubMed, as data sources",
    "aa2948209cc33b071dbf294822e72bb136678345": "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF15 , BIBREF15 , BIBREF15 , BIBREF17 or case profiles (e.g., dates, terms, locations and types) BIBREF2",
    "aa6d956c2860f58fc9baea74c353c9d985b05605": "Accuracy of best performing tasks",
    "aa7d327ef98f9f9847b447d4def04889b4508d7a": "Unanswerable",
    "ab0fd94dfc291cf3e54e9b7a7f78b852ddc1a797": "Rouge-1, Rouge-2 and Rouge-L",
    "ab54cd2dc83141bad3cb3628b3f0feee9169a556": "48,705",
    "ab9b0bde6113ffef8eb1c39919d21e5913a05081": "1) the corrected version of the same FCE training set on which the system is trained (450K tokens), and 2) example sentences extracted from the English Vocabulary Profile (270K tokens)",
    "ababb79dd3c301f4541beafa181f6a6726839a10": "12801 words are uttered in 117 turns",
    "abe2393415e533cb06311e74ed1c5674cff8571f": "F-score of 67.11%",
    "ac7f6497be4bcca64e75f28934b207c9e8097576": "Unanswerable",
    "ad08b215dca538930ef1f50b4e49cd25527028ad": "Yes",
    "ad1be65c4f0655ac5c902d17f05454c0d4c4a15d": "MCT, HIT, CNN, CNN, CNN, Trivia, CNN",
    "adbf33c6144b2f5c40d0c6a328a92687a476f371": "Yes",
    "ae7c93646aa5f3206cd759904965b4d484d12f83": "We define RL as the baseline model by optimizing $L_\\text{MLE}$ in Equation DISPLAYFORM19. ",
    "ae90c5567746fe25af2fcea0cc5f355751e05c71": "14 ample ",
    "aef607d2ac46024be17b1ddd0ed3f13378c563a6": "Unanswerable",
    "aefa333b2cf0a4000cd40566149816f5b36135e7": "CBOW and SkipGram implementation in Gensim library BIBREF7",
    "af34051bf3e628c1e2a00b110bb84e5f018b419f": "CNN-BiLSTM architecture to design our model does not contain 130k words segments, 83-dimensional pitch features",
    "af5730d82535464cedfa707a03415ac2e7a21295": "data from Wikipedia",
    "afb77b11da41cd0edcaa496d3f634d18e48d7168": "Unanswerable",
    "b06512c17d99f9339ffdab12cedbc63501ff527e": "No",
    "b08f88d1facefceb87e134ba2c1fa90035018e83": "No",
    "b0a18628289146472aa42f992d0db85c200ec64b": "F1 score of 60.98% on a similar task but this reported score is not directly comparable to the results on this task because of the multiple techniques mentioned in the training set",
    "b0d66760829f111b8fad0bd81ca331ddd943ef41": "RL, RL, RL, RL, RL, RL, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, RL, LC, R",
    "b0dbe75047310fec4d4ce787be5c32935fc4e37b": "noise,  the output dimensionality is INLINEFORM0 , the parameter INLINEFORM0 , where, the neural network is a concatenated sequence of semantic relations, which links a synset. For example, the paraphrase training examples, which contains the positions of the passage words that INLINEFORM2 (i.e. the passage and the passage and the question, the paragraphs in AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent and AddSent)",
    "b14217978ad9c3c9b6b1ce393b1b5c6e7f49ecab": "Unanswerable",
    "b1a068c1050e2bed12d5c9550c73e59cd5b1f78d": "16 F-TDNN layers, with dimension 153 and linear bottleneck layers of dimension 256.",
    "b1bc9ae9d40e7065343c12f860a461c7c730a612": "ShapeWorldICE",
    "b1ce129678e37070e69f01332f1a8587e18e06b0": "Microsoft ",
    "b1cf5739467ba90059add58d11b73d075a11ec86": "Yes",
    "b21bc09193699dc9cfad523f3d5542b0b2ff1b8e": "GENIA-2018",
    "b249b60a8c94d0e40d65f1ffdfcac527dab57516": "",
    "b2ecfd5480a2a4be98730e2d646dfb84daedab17": "TextWorld ACG, SemEval, KP20k, KP20k",
    "b3307d5b68c57a074c483636affee41054be06d1": "the unique features of the training set are: stuck-on sentences, complete sentences, and annotating the answer with masks",
    "b36f867fcda5ad62c46d23513369337352aa01d2": "WN18, the average accuracy of all parameters, weighted by the hyperparameter $\\eta $ , We construct negative triplets following the same setting used in BIBREF3 .",
    "b3d01ac226ee979e188a4141877a6d2a5482de98": "The ANLI dataset is available at github.com/mozilla-mozilla-anywhere The ANLI dataset is available at github.com/mozilla-anywhere The ANLI dataset is available at github.com/mozilla-anywhere The ANLI dataset is available at github.com/mozilla-anywhere",
    "b3de9357c569fb1454be8f2ac5fcecaea295b967": "1000 Arabic tweets with 30-dimensional vectors",
    "b46c0015a122ee5fb95c2a45691cb97f80de1bb6": "Unanswerable",
    "b49598b05358117ab1471b8ebd0b042d2f04b2a4": "WN18, the average accuracy of all parameters, weighted by the hyperparameter $\\eta $ , We construct negative triplets following the same setting used in BIBREF3 .",
    "b4f881331b975e6e4cab1868267211ed729d782d": "Unanswerable",
    "b5608076d91450b0d295ad14c3e3a90d7e168d0e": "No",
    "b591853e938984e6069d738371500ebdec50d256": "LSTM-based models of equal hidden size, LSTM-based models of equal embedding",
    "b5bc34e1e381dbf972d0b594fe8c66ff75305d71": "improving F1 score by 0.97 and 0.84 ",
    "b5e4866f0685299f1d7af267bbcc4afe2aab806f": "Unanswerable",
    "b634ff1607ce5756655e61b9a6f18bc736f84c83": "stocks, currencies but, yes",
    "b637d6393ef3af7462917b81861531022b291933": "Yes",
    "b65a83a24fc66728451bb063cf6ec50134c8bfb0": "Answer with content missing: (Formula) The dataset contains 2986 more baseline and 332 more baseline.",
    "b66c9a4021b6c8529cac1a2b54dacd8ec79afa5f": "Unanswerable",
    "b68f72aed961d5ba152e9dc50345e1e832196a76": "the publicly available OpenSubtitles2018 corpus BIBREF12",
    "b6ae8e10c6a0d34c834f18f66ab730b670fb528c": "Reddit",
    "b6f15fb6279b82e34a5bf4828b7b5ddabfdf1d54": "MNMT",
    "b6f466e0fdcb310ecd212fd90396d9d13e0c0504": "No",
    "b6f7fadaa1bb828530c2d6780289f12740229d84": "German, English INLINEFORM0 German and English INLINEFORM1 French",
    "b7381927764536bd97b099b6a172708125364954": "They evaluate the impact subword embeddings on their own vocabulary.",
    "b7c3f3942a07c118e57130bc4c3ec4adc431d725": "16,000 tweets",
    "b80a3fbeb49a8968e149955bdcf199556478eeff": "the TIMIT dataset contains speech from 462 speakers in training and 168 speakers in the test set, with 8 utterances each",
    "b85fc420eb2f77f6f14f375cc1fcc5155eb5c0a8": "Yes",
    "b8d0e4e0e820753ffc107c1847fe1dfd48883989": "Yes",
    "b8d7d055ddb94f5826a9aad7479b4a92a9c8a2f0": "RNNs, the gradients for each potential label can be obtained by back-propagation.",
    "b91671715ad4fad56c67c28ce6f29e180fe08595": "2013",
    "b962cc817a4baf6c56150f0d97097f18ad6cd9ed": "questions in the visual question-answering dataset BIBREF16 , BIBREF17",
    "b970f48d30775d3468952795bc72976baab3438e": "Unanswerable",
    "b9d07757e2d2c4be41823dd1ea3b9c7f115b5f72": "The RNN-based NMT with attention mechanism BIBREF0 has achieved remarkable performance on many bilingual translation tasks, It consists of encoder and decoder part, The input word sequence of source language are separately mapped into a INLINEFORM0 -dimensional vector space, INLINEFORM1",
    "b9d168da5321a7d7b812c52bb102a05210fe45bd": "Yes",
    "b9ea841b817ba23281c95c7a769873b840dee8d5": "Yes",
    "ba28ce9a2f7e8524243adf288cc3f11055e667bb": "No",
    "ba539cab80d25c3e20f39644415ed48b9e4e4185": "1-character attacks, we suggest a vector of the first character (mathbf {w_{iom )",
    "badc9db40adbbf2ea7bac29f2e4e3b6b9175b1f9": "homographic puns",
    "bb2de20ee5937da7e3e6230e942bec7b6e8f61ee": "For CNN, we used BERT, ELMo and FLAIR",
    "bb3267c3f0a12d8014d51105de5d81686afe5f1b": "He BIBREF29, TAC2010, NCEL-local",
    "bbb77f2d6685c9257763ca38afaaef29044b4018": "Unanswerable",
    "bc01853512eb3c11528e33003ceb233d7c1d7038": "Unanswerable",
    "bc16ce6e9c61ae13d46970ebe6c4728a47f8f425": "Unanswerable",
    "bc31a3d2f7c608df8c019a64d64cb0ccc5669210": "test-level knowledge, LUMS, LM, test accuracy",
    "bc4dca3e1e83f3b4bbb53a31557fc5d8971603b2": "SimLex BIBREF19 and Rare Word (RW) BIBREF20 word similarity datasets, Google Semantic (GSem) analogies BIBREF9, WC$, C$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$, WC$",
    "bc67b91dd73acded2d52fd4fee732b7a9722ea8b": " word co-occurrence networks, word wait, propagation, reading, and image retrieval",
    "bc730e4d964b6a66656078e2da130310142ab641": "Logistic Regression (LR) BIBREF1, Multilayer Perceptron (MLP), level 3 workers on the Figure-Eight crowdsourcing platform for our experiments.",
    "bc84c5a58c57038910f7720d7a784560054d3e1a": "German, Dutch, Russian, Italian, Chinese",
    "bd40f33452da7711b65faaa248aca359b27fddb6": "Majority Class, Majority Class, Multilingual Berteline, Multilingual Berteline",
    "bd419f4094186a5ce74ba6ac1622b24e29e553f4": "the baseline models as well as the HUMAN measured performance on the task",
    "bd5bd1765362c2d972a762ca12675108754aa437": "The PDTB dataset documents its annotations as a list of discourse relations, with each relation associated with its two discourses",
    "bd6dc38a9ac8d329114172194b0820766458dacc": "BIBREF0, ELAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, LAN, Lanese)",
    "bdc91d1283a82226aeeb7a2f79dbbc57d3e84a1a": "BERTBase-PNsmth, GLUE",
    "bdf93053b1b9b0a21f77ed370cf4d5a10df70e3e": "system has been significantly degraded by, system has been significantly degraded by, system has been significantly degraded by, system has been significantly degraded by, system has been significantly degraded by, system has been significantly degraded by, system has been significantly degraded by, system has been significantly degraded by, system has been significantly degraded by, system been significantly degraded by, system been significantly degraded by, system been significantly degraded by, system been significantly degraded by, system been significantly non-compact system has been significantly degraded by, system has been significantly degraded by, system has been significantly degraded by, system been significantly degraded by, system been significantly degraded by, system been significantly degraded by, system been significantly degraded by, system been significantly degraded by, system been significantly degraded by, system been significantly",
    "beac555c4aea76c88f19db7cc901fa638765c250": "attention loss rate (AER) BIBREF14 , BIBREF7 , BIBREF7 , BIBREF8 , ParZu",
    "bf3b27a4f4be1f9ae31319877fd0c75c03126fd5": "13 different hyperparameter settings of PARENT-C",
    "bf52c01bf82612d0c7bbf2e6a5bb2570c322936f": " the entire summary without stopwords and numeric values, we refer to the small units, noun Phrases (NP), Keywords (KW)",
    "bfbd6040cb95b179118557352e8e3899ef25c525": "No",
    "bfc1de5fa4da2f0e301fd22aea19cf01e2bb5b31": "English, Translate-Test, MultiNLI, SQuAD, MultiNLI, MultiNLI, MultiNLI, MultiNLI, MultiNLI",
    "bfc2dc913e7b78f3bd45e5449d71383d0aa4a890": "RL model is a deep library of learning algorithm.",
    "c00ce1e3be14610fb4e1f0614005911bb5ff0302": " we extract the sentiment of the tweets by employing EffectWordNet BIBREF13, SenticNet BIBREF14, NRC BIBREF10",
    "c01784b995f6594fdb23d7b62f20a35ae73eaa77": "CoinCollector games have been proposed to address the challenges associated with reward sparsity.",
    "c08aab979dcdc8f4fe8ec1337c3c8290ab13414e": "2017",
    "c09a92e25e6a81369fcc4ae6045491f2690ccc10": "Unanswerable",
    "c0af8b7bf52dc15e0b33704822c4a34077e09cd1": "LSTM RNNs outperform conventional RNNs for speech recognition system",
    "c0bee6539eb6956a7347daa9d2419b367bd02064": "Yes",
    "c0e341c4d2253eb42c8840381b082aae274eddad": " link between entity names and relation detection",
    "c17b609b0b090d7e8f99de1445be04f8f66367d4": "CNN/DailyMail news highlights, XSum ",
    "c1c44fd96c3fa6e16949ae8fa453e511c6435c68": "Unanswerable",
    "c21b87c97d1afac85ece2450ee76d01c946de668": "Unanswerable",
    "c22394a3fb0dbf2fc7d3a70ad6435803f5a16ebd": "WER, gender, Gender representation, gender bias evaluation procedure",
    "c262d3d1c5a8b6fef6b594d5eee86bc2b09e3baf": "Yes",
    "c2b8ee872b99f698b3d2082d57f9408a91e1b4c1": "Deeplearning4j framework",
    "c2cb6c4500d9e02fc9a1bdffd22c3df69655189f": "Yes",
    "c2d1387e08cf25cb6b1f482178cca58030e85b70": "\n Yes",
    "c2e475adeddcdc4d637ef0d4f5065b6a9b299827": "BLEU-4, NIST-4 and ROUGE-4",
    "c2eb743c9d0baf1781c3c0df9533fab588250af3": "Model Variations in SST-2, data samples annotated with `neutral' are ignored from training and evaluation",
    "c32adef59efcb9d1a5b10e1d7c999a825c9e6d9a": "English test set to better understand the remaining shortcomings of the approach. ",
    "c34e80fbbfda0f1786d3b00e06cef5ada78a3f3c": "Yes",
    "c35806cf68220b2b9bb082b62f493393b9bdff86": "accuracy, accuracy, accuracy, and image, we derive comparable results on SST-2, SST-5, and competitive accuracy on SST-5,  Table TABREF355 and SST-5",
    "c37f65c9f0d543a35c784263b79236ccf1c44fac": "  we obtained the highest scores with the METEOR and BLEU-3 metrics",
    "c4628d965983934d7a2a9797a2de6a411629d5bc": "No",
    "c497e8701060583d91bb64b9f9202d40047effc4": "tweets",
    "c49ee6ac4dc812ff84d255886fd5aff794f53c39": "Yes",
    "c571deefe93f0a41b60f9886db119947648e967c": " CUIs are extracted using Apache cTAKES BIBREF19 and filtered by removing the CUIs that are already subsumed by a longer spanning CUI.",
    "c59078efa7249acfb9043717237c96ae762c0a8c": "10,000 documents of 500 words each",
    "c598028815066089cc1e131b96d6966d2610467a": "No",
    "c5abe97625b9e1c8de8208e15d59c704a597b88c": "Zork1 has 0.98 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all actions, 0.998 penalty on all",
    "c5b0ed5db65051eebd858beaf303809aa815e8e5": "Yes",
    "c6a0b9b5dabcefda0233320dd1548518a0ae758e": "inappropriate listening",
    "c70bafc35e27be9d1efae60596bc0dd390c124c0": "Yes",
    "c74185bced810449c5f438f11ed6a578d1e359b4": "Unanswerable",
    "c7486d039304ca9d50d0571236429f4f6fbcfcf7": "Dutch, 21.76%",
    "c77359fb9d3ef96965a9af0396b101f82a0a9de6": "the recipe name as a sequence of tokens, a partial list of ingredients, and a calorie level",
    "c7b6e6cb997de1660fd24d31759fe6bb21c7863f": "Unanswerable",
    "c7eb71683f53ab7acffd691a36cad6edc7f5522e": "Yes",
    "c81f215d457bdb913a5bade2b4283f19c4ee826c": "Waseem et al. BIBREF5, Davidson et al. BIBREF9, Waseem et al. BIBREF10",
    "c8541ff10c4e0c8e9eb37d9d7ea408d1914019a9": "South African languages still under resourced from the point of view of building data driven by by by by by by by by by by by by by by NCHLT text corpora BIBREF7, The WiLI-2018 benchmark dataset BIBREF4",
    "c85b6f9bafc4c64fc538108ab40a0590a2f5768e": "Our semi-supervised approach is quite straightforward: first calculating the benefits of adding each lexicon each",
    "c87fcc98625e82fdb494ff0f5309319620d69040": "Galatasaray, Galatasaray, Galatasaray, Galatasaray",
    "c88a846197b72d25e04ec55f00ee3e72f655504c": " A semi-structured, multilayer network which has been used as a point of truth for all history, a single-family conflict between the two nations for the two countries, a dispute over the unresolved Kashri people, conflict over the unresolved Kashri people, conflict over the unresolved Kashmir problem",
    "c9305e5794b65b33399c22ac8e4e024f6b757a30": "best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model among author's submissions, best performing model  best performing model among author's subms, best performing model among author's subms, best performing model among author's subm after analysis",
    "c9b8d3858c112859eabee54248b874331c48f71b": "LSTM layer size and attention layer size is 100; images are available in Track 2 ",
    "c9bc6f53b941863e801280343afa14248521ce43": "English Wikipedia",
    "ca4daafdc23f4e23d933ebabe682e1fe0d4b95ed": "lexicon based classifier",
    "ca5a82b54cb707c9b947aa8445aac51ea218b23a": "By interacting with users, it generates a ranked list of relevant questions based on the questions.",
    "cb12c19f9d14bef7b2f778892d9071eea2d6c63d": "BBCSport, BBCSport, BBCSport",
    "cb196725edc9cdb2c54b72364f3bbf7c76471490": "Yes",
    "cb384dc5366b693f28680374d31ff45356af0461": "No",
    "cb6a8c642575d3577d1840ca2f4cd2cc2c3397c5": "Yes",
    "cb77d6a74065cb05318faf57e7ceca05e126a80d": "CoNLL-2003 IOB format25, BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLSTM-CNN-CRF BiLST-CNN-CRF BiLST-C-CRF BiLST-C-CRF BiLST-C-CRF BiLST-C-CRF BiLST-C-CRF BiLST-C-CRF BiLST-C-CRF BiLST-C-CRF Bi-C-C-C-C-C-C-C-C-C-C CoNLL-2003 IO format25, BiLSTM-CNN",
    "cc354c952b5aaed2d4d1e932175e008ff2d801dd": "Unanswerable",
    "cc608df2884e1e82679f663ed9d9d67a4b6c03f3": "Unanswerable",
    "cc850bc8245a7ae790e1f59014371d4f35cd46d7": "input article:position-entity (AEP) and (ii) article-section (ASP) placement",
    "cd06d775f491b4a17c9d616a8729fd45aa2e79bf": "1,000 randomly selected tweets contains more than twice as many tweets about Trump than about the other candidates",
    "cd2878c5a52542ddf080b20bec005d9a74f2d916": "Standard Occupational Classification (SOC) system, a train set, a development set, and test set",
    "cd32a38e0f33b137ab590e1677e8fb073724df7f": "CoNLL 2014 Shared Task dataset (30K tokens) and the two alternative annotations of the CoNLL 2014 Shared Task dataset (30K tokens)",
    "ce0e2a8675055a5468c4c54dbb099cfd743df8a7": "The authors are examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of examples of of examples of of MEM.",
    "ce2b921e4442a21555d65d8ce4ef7e3bde931dfc": "French, Russian, Hindi, Vietnamese",
    "ce6a3ca102a5ee62e86fc7def3b20b1f10d1eb25": "Yes",
    "ceb767e33fde4b927e730f893db5ece947ffb0d8": "area,laws, words, and cases",
    "cee8cfaf26e49d98e7d34fa1b414f8f31d6502ad": "CoVoST has over 327 hours of German speeches, 37-hour Persian, Dutch, Russian, Italian, Chinese",
    "cf171fad0bea5ab985c53d11e48e7883c23cdc44": "Twitter",
    "cf874cd9023d901e10aa8664b813d32501e7e4d2": "BioNLP'16 Shared Tasks has also introduced some Relation Extraction tasks, in particular the BB3-event subtask that involves prediction of trigger words over six event types, Transcription of Biomedicals and Biomedicals",
    "cfbec1ef032ac968560a7c76dec70faf1269b27c": "Unanswerable",
    "cfcdd73e712caf552ba44d0aa264d8dace65a589": "The data comes from Google's DialogState Tracking Challenge dataset and Rasa dataset.",
    "d004ca2e999940ac5c1576046e30efa3059832fa": "The different types of harassment and tweets are split into three sub-categories which are direct harassment, sexual and physical harassment",
    "d00bbeda2a45495e6261548710afa6b21ea32870": "Unanswerable",
    "d015faf0f8dcf2e15c1690bbbe2bf1e7e0ce3751": "offensive (OFF), non-aggressive, covertly aggressive, and overtly aggressive",
    "d01c51155e4719bf587d114bcd403b273c77246f": "XNLI , UD parsing, Random Attachment (LASER)",
    "d087539e6a38c42f0a521ff2173ef42c0733878e": "The up-projection",
    "d1ec42b2b5a3c956ff528543636e024bfde5e5ba": "ARL, ARL, ARL, ROUGE-L F1 reward",
    "d201b9992809142fe59ae74508bc576f8ca538ff": "Yes",
    "d27438b11bc70e706431dda0af2b1c0b0d209f96": "Unanswerable",
    "d28d86524292506d4b24ae2d486725a6d57a3db3": "ROUGE-1, ROUGE-2 and ROUGE-L on the CNN/Daily Mail dataset, we compare the performance of many new approaches with our model",
    "d3093062aebff475b4deab90815004051e802aa6": "The UTCNN",
    "d3aa0449708cc861a51551b128d73e11d62207d2": "They use in their propsoed framework (for the KBQA))",
    "d3ca5f1814860a88ff30761fec3d860d35e39167": "EVBCorpus, EVBNews, EVBNews, EVBNews, EVBNews",
    "d3dbb5c22ef204d85707d2d24284cc77fa816b6c": "1.0 points in terms of F1 score",
    "d3ff2986ca8cb85a9a5cec039c266df756947b43": "Unanswerable",
    "d41e20ec716b5904a272938e5a8f5f3f15a7779e": "collectively, quantify negative evaluations of a target group, denial of agency, moral disgust, and use of non-human adjectives",
    "d46c0ea1ba68c649cc64d2ebb6af20202a74a3c7": "SimLex BIBREF19 and Rare Word (RW) BIBREF20 word similarity datasets, Google Semantic (GSem) analogies BIBREF9, WC$, C$, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC, WC,",
    "d4db7df65aa4ece63e1de813e5ce98ce1b4dbe7f": "the number of followers of all the handles in set$P$ could increase significantly.",
    "d4e5e3f37679ff68914b55334e822ea18e60a6cf": "Women and men words in the text are more inclined to mention one over the other, so it can also be considered a form of bias",
    "d509081673f5667060400eb325a8050fa5db7cc8": "Unanswerable",
    "d51dc36fbf6518226b8e45d4c817e07e8f642003": "30 ",
    "d53299fac8c94bd0179968eb868506124af407d1": "Unanswerable",
    "d571e0b0f402a3d36fb30d70cdcd2911df883bc7": "Yes",
    "d5a8fd8bb48dd1f75927e874bdea582b4732a0cd": "Yes",
    "d604f5fb114169f75f9a38fab18c1e866c5ac28b": "weighting of the similarity metric features features using SVM rating",
    "d6191c4643201262a770947fc95a613f57bedb6b": "DUC and TAC208",
    "d6401cece55a14d2a35ba797a0878dfe2deabedc": "The same test for the same test was given in the French.",
    "d64383e39357bd4177b49c02eb48e12ba7ffd4fb": "Lexicon Embeddings, AddSent, AddSent, AddOneSent, AddOneSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSent, AddSantio",
    "d650101712e36594bd77b45930a990402a455222": "Legal Reading Comprehension (LRC) framework",
    "d667731ea20605580c398a1224a0094d1155ebbb": "No",
    "d67c01d9b689c052045f3de1b0918bab18c3f174": "3555 copyright-free books to extract CN examples and 10507 books for NE examples, for comparison the CBT dataset ",
    "d6e353e0231d09fd5dcba493544d53706f3fe1ab": "Unanswerable",
    "d6ea7a30b0b61ae126b00b59d2a14fff2ef887bf": "Unanswerable",
    "d7644c674887ca9708eb12107acd964ae53b216d": "Unanswerable",
    "d78f7f84a76a07b777d4092cb58161528ca3803c": "Precision, Recall, and F1 scores on named entity and nominal mention are shown in a Chinese corpus that the word label \"End\" has a better performance than \"Begin\". This motivates us carry out a backward greedy search over each sentence's label sequence to identify word boundaries.",
    "d7b60abb0091246e29d1a9c28467de598e090c20": "The baseline is the baseline.",
    "d859cc37799a508bbbe4270ed291ca6394afce2c": "Unanswerable",
    "d8627ba08b7342e473b8a2b560baa8cdbae3c7fd": "Yes",
    "d915b401bb96c9f104a0353bef9254672e6f5a47": "17.00% on all metrics.",
    "d93c0e78a3fe890cd534a11276e934be68583f4b": "Unanswerable",
    "d9412dda3279729e95fcb35cbed09e61577a896e": "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF15 , BIBREF15 , BIBREF15 , BIBREF17 or case profiles (e.g., dates, terms, locations and types) BIBREF2",
    "d98847340e46ffe381992f1a594e75d3fb8d385e": " parallel processing of the RQE, LR+IR method, RTE-2 and RTE-3",
    "d9980676a83295dda37c20cfd5d58e574d0a4859": "backtrans-bad: this is the most expensive methodo encantation",
    "d9b6c61fc6d29ad399d27b931b6cb7b1117b314a": "Question Answer with content missing: (formula) BIBREF17 bordes2014question, (formula) BIBREF17 bordes2014question, (formula) BIBREF17 bordes2014question, (formula) BIBREF17 bordes2014question, (formula) BIBREF17 bordes2014question, (formula) BIBREF17 bordes2014question, (formula) BIBREF17 bordes2014question, (formula)",
    "da55bd769721b878dd17f07f124a37a0a165db02": "Regular Expressions (RegEx) and Elasticsearch (ES) API",
    "da9c0637623885afaf023a319beee87898948fe9": "Yes",
    "dac087e1328e65ca08f66d8b5307d6624bf3943f": "Support Vector Machines (SVM), Adaboost, and Random Forests are adopted to evaluate our extracted features., We test each classification algorithm with scikit-learn BIBREF9 and run a 10-fold cross validation.",
    "db72a78a7102b5f0e75a4d9e1a06a3c2e7aabb21": " the word \u201ckatab\u201d (\u0643\u062a\u0627\u0628> \u2013 book) and the \u201ckut$\\sim $Ab\u201d (\u0643\u062a\u0627\u0628> \u2013 book)",
    "dc1cec824507fc85ac1ba87882fe1e422ff6cffb": "10000 questions",
    "dc2a2c177cd5df6da5d03e6e74262bf424850ec9": "Unanswerable",
    "dca86fbe1d57b44986055b282a03c15ef7882e51": "Unanswerable",
    "dcc1115aeaf87118736e86f3e3eb85bf5541281c": "a level of confidence that the selected class would be available in the general context than the one",
    "dcea88698949da4a1bd00277c06df06c33f6a5ff": "The proposed task a good proxy for the general-purpose sequence to sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence sequence box music play music video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video video",
    "dd09db5eb321083dba16c2550676e60682f9a0cd": "Banknote, TextCNN",
    "dd20d93166c14f1e57644cd7fa7b5e5738025cd0": " two networks, one for each time use of a single layer, re-tweeting split cross validation, evaluated on the US dataset, and a third party-of-the-brain connected component of a given graph",
    "dd53baf26dad3d74872f2d8956c9119a27269bd5": " we randomly sampled a seed dataset consisting of 1,200 turns and manually reviewed them",
    "dd6b378d89c05058e8f49e48fd48f5c458ea2ebc": "BiLSTM-CRF, BERT architecture for deriving text, Bidirectional Encoder Representations (BERT), outperformed previous state-of-the-art methods",
    "dd76130ec5fac477123fe8880472d03fbafddef6": "Unanswerable",
    "ddb23a71113cbc092cbc158066d891cae261e2c6": "Twitter article",
    "ddf5e1f600b9ce2e8f63213982ef4209bab01fd8": "37,111 and 5,351 question answer pairs in the training set",
    "de0b650022ad8693465242ded169313419eed7d9": "Unanswerable",
    "de3b1145cb4111ea2d4e113f816b537d052d9814": "F-measure of 131.9 point increase in F-measure for all categories and more interestingly our result showed little variance between different emotions compare to results by Wang et al.",
    "de53af4eddbc30c808d90b8a11a29217d377569e": "Facebook",
    "de5b6c25e35b3a6c5e40e350fc5e52c160b33490": "Unanswerable",
    "de830c534c23f103288c198eb19174c76bfd38a1": "ArXiv, ArXiv, ArXiv, ArXiv, ArXiv, ArXiv, ArXiv, ArXiv",
    "dea9e7fe8e47da5e7f31d9b1a46ebe34e731a596": "The system consists of pre-processing of the tweets in the dataset and the feature extraction followed by the method used to identify humor in tweets.",
    "deb89bca0925657e0f91ab5daca78b9e548de2bd": "KARA ONE, KARA ONE, KARA ONE, KARA ONE, KOUL 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,",
    "df0257ab04686ddf1c6c4d9b0529a7632330b98e": "10 CoinCollector games with the hardest setting used by BIBREF8",
    "df5a4505edccc0ee11349ed6e7958cf6b84c9ed4": "1. Loaded language.",
    "df6d327e176740da9edcc111a06374c54c8e809c": " primary method: LAS: LEXIS: \nN-grams, POS, Hierarchical features: A baseline bag-of-words model incorporating both single-label hierarchical levels",
    "df95b3cb6aa0187655fd4856ae2b1f503d533583": "Unanswerable",
    "dfca00be3284cc555a6a4eac4831471fb1f5875b": "37,500 training samples with 75 abbreviation terms, 93-sense pairs",
    "e0122fc7b0143d5cbcda2120be87a012fb987627": "WAP results are reported at 8.02 on 8.03 8.03 ",
    "e025061e199b121f2ac8f3d9637d9bf987d65cd5": "Unanswerable",
    "e0e379e546f1da9da874a2e90c79b41c60feb817": "Unanswerable",
    "e101e38efaa4b931f7dd75757caacdc945bb32b4": "Unanswerable",
    "e1ab11885f72b4658263a60751d956ba661c1d61": "100 words",
    "e2b0cd30cf56a4b13f96426489367024310c3a05": "Unanswerable",
    "e2db361ae9ad9dbaa9a85736c5593eb3a471983d": "Phrase level opinion polarity from newswire BIBREF28",
    "e2e977d7222654ee8d983fd8ba63b930e9a5a691": "RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling, RNN modeling",
    "e330e162ec29722f5ec9f83853d129c9e0693d65": "Yes",
    "e35a7f9513ff1cc0f0520f1d4ad9168a47dc18bb": "KyTea-segmented Japanese texts and pyvi-segmented Vietnamese texts",
    "e35c2fa99d5c84d8cb5d83fca2b434dcd83f3851": "we compare our approach (FacTweet) to the following set of baselines: Twitter, suspicious Twitter, follow the news in descending way and we split them into $N$ chunks. Each chunk consists of a sorted sequence of a sorted sequence of tweets labeled by the label of its corresponding account",
    "e374169ee10f835f660ab8403a5701114586f167": "54 stars, 5 news pictures are included in Table TABREF16.",
    "e3a2d8886f03e78ed5e138df870f48635875727e": "ironic style, we use denoising auto-encoder and back-translation to build up language models for both styles (section SECRE14 )",
    "e3c9e4bc7bb93461856e1f4354f33010bc7d28d5": "SVM with lexical features in accordance with previous works BIBREF16 , BIBREF17 , BIBREF15 , BIBREF15 , BIBREF15 , BIBREF17 or case profiles (e.g., dates, terms, locations and types) BIBREF2",
    "e431661f17347607c3d3d9764928385a8f3d9650": "10-fold decrease",
    "e438445cf823893c841b2bc26cdce32ccc3f5cbe": "Benchmark, BLecmeve, Benchmark, Inception, Benchmark, Inception, Benchmark, Inception, Benchmark, Inception, Benchmark, Inception, Benchmarkenzaology",
    "e44a6bf67ce3fde0c6608b150030e44d87eb25e3": "Unanswerable",
    "e48e750743aef36529fbea4328b8253dbe928b4d": "The train and dev set were merged to perform 10-fold cross validation.",
    "e4a315e9c190cf96493eefe04ce4ba6ae6894550": "Unanswerable",
    "e54257585cc75564341eb02bdc63ff8111992f82": "144 articles collected from the ACM Digital Library (conference and workshop papers), 144 articles collected from the ACM Digital Library (conference and workshop papers). 144 articles collected from the ACM Digital Library (conference and workshop papers). 144 articles collected from the ACM Digital Library (conference and workshop papers).",
    "e587559f5ab6e42f7d981372ee34aebdc92b646e": "Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2letter, Wav2eb for Wav2eberserserserserserserserserserserserserserserserserknowingbeyondnowingnowingnowingnowingnowingnowingnowoldborough for all decoding performance of all statistical N-gram LMs",
    "e5bc73974c79d96eee2b688e578a9de1d0eb38fd": "space for further improvement on the CBT",
    "e5c8e9e54e77960c8c26e8e238168a603fcdfcc6": "No",
    "e6583c60b13b87fc37af75ffc975e7e316d4f4e0": "Event-related responses",
    "e79a5b6b6680bd2f63e9f4adbaae1d7795d81e38": "Dutch, 21.76% Dutch, 21.76% English",
    "e807d347742b2799bc347c0eff19b4c270449fee": " BERT 2.0",
    "e82fa03f1638a8c59ceb62bb9a6b41b498950e1f": "MFS",
    "e831041d50f3922265330fcbee5a980d0e2586dd": "The average number of seconds a subject spends per sentence",
    "e838275bb0673fba0d67ac00e4307944a2c17be3": "1000 Arabic tweets with 10000 Arabic tweets",
    "e86130c5b9ab28f0ec539c2bed1b1ae9efb99b7d": "Unanswerable",
    "e8a32460fba149003566969f92ab5dd94a8754a4": "Unanswerable",
    "e8f969ffd637b82d04d3be28c51f0f3ca6b3883e": "Lead-3 model",
    "e949b28f6d1f20e18e82742e04d68158415dc61e": " participating systems, our submissions are ranked 3rd and 4th in FLC, SLC tasks, respectively.",
    "e97186c51d4af490dba6faaf833d269c8256426c": "Yes",
    "e9cfbfdf30e48cffdeca58d4ac6fdd66a8b27d7a": "collective a corpus of 30 topics",
    "ea56148a8356a1918bedcf0a99ae667c27792cfe": "Rei2016, Cahill2014a used different methods and the same sentences extracted from the English Vocabulary Profile (270K)",
    "eac9dae3492e17bc49c842fb566f464ff18c049b": " the data are embedded within the argumentation mining field to date predictor structure. ",
    "eb2d5edcdfe18bd708348283f92a32294bb193a5": "Zork1",
    "ebf0d9f9260ed61cbfd79b962df3899d05f9ebfb": "Unanswerable",
    "ecc63972b2783ee39b3e522653cfb6dc5917d522": " we use a shallow architecture, which enables fast training, (2) computational datasets vary by the number of tweets per tweets.",
    "ecd5770cf8cb12cb34285e26ab834301c17c53e1": "VizWiz, Yu-Chuan, Suyogan",
    "ed2eb4e54b641b7670ab5a7060c7b16c628699ab": "the CNN/DailyMail (CNNDM) dataset BIBREF34, BIBREF11, the New York Times dataset BIBREF35, the New York Times dataset BIBREF35",
    "ed67359889cf61fa11ee291d6c378cccf83d599d": "38,182 videos",
    "ed6a15f0f7fa4594e51d5bde21cc0c6c1bedbfdc": "18 fine-grained NER labels in the dataset",
    "eda4869c67fe8bbf83db632275f053e7e0241e8c": "Paraphrase Database (containing noisy phrase pairs)",
    "ee2ad0ab64579cffb60853db6a8c0f971d7cf0ff": "16 F-TDNN layers, with dimension 153 and linear bottleneck layers of dimension 256.",
    "ee2c9bc24d70daa0c87e38e0558e09ab97feb4f2": "No",
    "ee417fea65f9b1029455797671da0840c8c1abbe": "No",
    "ee7e9a948ee6888aa5830b1a3d0d148ff656d864": "Unanswerable",
    "ef3567ce7301b28e34377e7b62c4ec9b496f00bf": "\n Unanswerable",
    "ef396a34436072cb3c40b0c9bc9179fee4a168ae": "Their proposed model is a multi-layer perception model with a grammatical tree structure and a non-zero tag.",
    "ef4dba073d24042f24886580ae77add5326f2130": "The baseline model has three main components. First, we make a new bi-LSTM, named by the crowdsable SEARCH and use the target dataset.",
    "ef7212075e80bf35b7889dc8dd52fcbae0d1400a": "First, the extracted entities may be ambiguous, The summary contains four words that refer to different entities extracted from the original text.",
    "efe9bad55107a6be7704ed97ecce948a8ca7b1d2": "up-projection, up-projection",
    "f03112b868b658c954db62fc64430bebbaa7d9e0": "No",
    "f03df5d99b753dc4833ef27b32bb95ba53d790ee": "1) spread tweets containing fake news and viral tweets containing not containing fake news",
    "f0848e7a339da0828278f6803ed7990366c975f0": "Yes",
    "f0b1d8c0a44dbe8d444a5dbe2d9c3d51e048a6f6": "1,042,647 dialogue rates are compared to the mean of the 40%",
    "f0b2289cb887740f9255909018f400f028b1ef26": "online harassment",
    "f161e6d5aecf8fae3a26374dcb3e4e1b40530c95": " between 84.12 and 89.57",
    "f17ca24b135f9fe6bb25dc5084b13e1637ec7744": "Simple Word Interaction (SWIM) with tensors that captures both linear and quadratic representations of the linear and quadratic representations of the linear and quadratic representations of the linear and quadratic representations of the linear and quadratic representations of the linear and quadratic representations of the linear and quadratic representations of the linear and quadratic representations of the linear and quadratic representations of linear and quadratic representations of linear and quadratic representations of linear and quadratic representations of linear and quadratic representations of quadratic and quadratic expressions of quadratic expressions of quadratic expressions of quadratic expressions of quadratic expressions of sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences sentences",
    "f1e90a553a4185a4b0299bd179f4f156df798bce": "KP20k, Inspec, Krapivin, NUS, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemEval, SemE Sem KP20k, Inspec, Krapivin, NUS, SemEval, SemEval, SemEval, SemE SemEval, SemE SemEval, SemE SemEval, SemE SemEval, SemE SemE SemEval, SemE SemE SemE, SemE SemE SemE SemE, SemE SemE Sem",
    "f1f1dcc67b3e4d554bfeb508226cdadb3c32d2e9": "SemEval-2016 Challenge Task 5 BIBREF27 , BIBREF28 , Dutch, 21.76% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 10.71% English, 1",
    "f2155dc4aeab86bf31a838c8ff388c85440fce6e": "Yes",
    "f225a9f923e4cdd836dd8fe097848da06ec3e0cc": "SQuAD dataset, SQuAD dataset, SQuAD dataset, SQuAD dataset, SQuAD dataset, SQuAD dataset",
    "f2e8497aa16327aa297a7f9f7d156e485fe33945": " we focus on documents exclusively available through PubMed Central (PMC).",
    "f318a2851d7061f05a5b32b94251f943480fbd15": "The content of these two corpora were analyzed are by psychologists",
    "f3c204723da53c7c8ef4dc1018ffbee545e81056": "Yes",
    "f428618ca9c017e0c9c2a23515dab30a7660f65f": "Multi Layer Perception Naive Bayes (GVD)",
    "f4496316ddd35ee2f0ccc6475d73a66abf87b611": "The contributions of this paper are threefold: First, we propose two low cost concept embedding models which requires few hours rather than days to train on similar computing resources",
    "f56d07f73b31a9c72ea737b40103d7004ef6a079": "BIBREF24 , BIBREF15 , BIBREF15",
    "f59f1f5b528a2eec5cfb1e49c87699e0c536cc45": "1040 words",
    "f5e6f43454332e0521a778db0b769481e23e7682": "MNMT",
    "f651cd144b7749e82aa1374779700812f64c8799": "BLEU BIBREF5, SBMT-SARI",
    "f697d00a82750b14376fe20a5a2b249e98bebe9b": "                                                                                                                                                                                                      ",
    "f71b52e00e0be80c926f153b9fe0a06dd93af11e": "Unanswerable",
    "f7a89b9cd2792f23f2cb43d50a01b8218a6fbb24": "SnapCaptions dataset",
    "f7d0fa52017a642a9f70091a252857fccca31f12": "SST-2, SST-5, SST-5",
    "f7ed3b9ed469ed34f46acde86b8a066c52ecf430": "1) \u201ccat\u201d, we mark beginning and end with angled brackets and use all n-grams of length 3 to 6 as subwords, yielding $Sarftextnormal {catrangle $117,111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111121112111211211212 2) \u201cmarvelous\u201d (LI)",
    "f85ca6135b101736f5c16c5b5d40895280016023": "CLEF corpus, Transformer, RAT",
    "f85f2a532e7e700d9f8f9c09cd08d4e47b87bdd3": "Unanswerable",
    "f875337f2ecd686cd7789e111174d0f14972638d": "BIBREF19",
    "f88036174b4a0dbf4fe70ddad884d16082c5748d": "No",
    "f8c1b17d265a61502347c9a937269b38fc3fcab1": "Unanswerable",
    "f8da63df16c4c42093e5778c01a8e7e9b270142e": "\nWe have found that it has the highest possible impact on the performance of our tests by 50% using this method and its primary goal is to maintain the performance of highest possible quality of the human segmentations",
    "f8f4e4a50d2b3fbd193327e79ea32d8d057e1414": "5 languages are relatively low resource (especially Turkmenian, Haitian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmenian, Turkmon).",
    "f903396d943541a8cc65edefb04ca37814ed30dd": "Reddit",
    "f94b53db307685d572aefad52cd55f53d23769c2": "We observe that the ranking of samples",
    "f9aa055bf73185ba939dfb03454384810eb17ad1": "Unanswerable",
    "f9bf6bef946012dd42835bf0c547c0de9c1d229f": "Unanswerable",
    "f9edd8f9c13b54d8b1253ed30e7decc1999602da": " a set of fixed phrases which are used to verify speakers in text-dependent mode, Each speaker utters 5 Persian phrases, and if the speaker can read English, 5 random sequences of English digits are also recorded in each session",
    "f9f59c171531c452bd2767dc332dc74cadee5120": "14 participants, with each prompt presented 11 times to each individual",
    "fa30a938b58fc05131c3854f12efe376cbad887f": "Unanswerable",
    "fa527becb8e2551f4fd2ae840dbd4a68971349e0": "CoNLL\u2013SIGMORPHON 2018 baseline system",
    "fabcd71644bb63559d34b38d78f6ef87c256d475": "CWS, CITYU",
    "fabf6fdcfb4c4c7affaa1e4336658c1e6635b1bf": "SVM",
    "fb1227b3681c69f60eb0539e16c5a8cd784177a7": "entity-document and temporal features",
    "fb2b536dc8e442dffab408db992b971e86548158": "Unanswerable",
    "fb3d30d59ed49e87f63d3735b876d45c4c6b8939": "ADWS kernel BIBREF18",
    "fb5fb11e7d01b9f9efe3db3417b8faf4f8d6931f": "a logistic regression and three neural models., LSTM",
    "fbaf060004f196a286fef67593d2d76826f0304e": "Dutch, 21.76%",
    "fc1679c714eab822431bbe96f0e9cf4079cd8b8d": "Unanswerable",
    "fc4ae12576ea3a85ea6d150b46938890d63a7d18": "No",
    "fd0a3e9c210163a55d3ed791e95ae3875184b8f8": "Kaldi s5 recipe BIBREF18",
    "fd2c6c26fd0ab3c10aae4f2550c5391576a77491": "Unanswerable",
    "fd753ab5177d7bd27db0e0afc12411876ee607df": "the labels were obtained using distant supervision, assuming that all articles from a given news outlet share the label of that outlet, which inevitably introduces noise BIBREF6.",
    "fd8e23947095fe2230ffe1a478945829b09c8c95": "Unanswerable",
    "fde700d5134a9ae8f7579bea1f1b75f34d7c1c4c": "Unanswerable",
    "fe2666ace293b4bfac3182db6d0c6f03ea799277": "challenge relates to ambiguous words and variant recognition",
    "feafcc1c4026d7f55a2c8ce7850d7e12030b5c22": "They use left-context-only decoder, thus do not have complete context when predicting each word.",
    "feb448860918ef5b905bb25d7b855ba389117c1f": "Unanswerable",
    "ff338921e34c15baf1eae0074938bf79ee65fdd2": " path, LATs, LATs, and F-measure",
    "ff6c9af28f0e2bb4fb6a69f124665f8ceb966fbc": "Galatasaray (namely Target-1) and Felipe (no)",
    "ffa7f91d6406da11ddf415ef094aaf28f3c3872d": "Unanswerable",
    "ffde866b1203a01580eb33237a0bb9da71c75ecf": "11,000 speakers and over 60 accents, 800-channel serial-o-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-no-",
    "ffeb67a61ecd09542b1c53c3e4c3abd4da0496a8": "They define a concept map that represents its most important content, satisfies a specified size limit and is connected.",
    "fff5c24dca92bc7d5435a2600e6764f039551787": "By simply adding a second key, transforming the number of phrases into a single sequence with a delimiter INLINEFORM0 , and using it to interpolate the abstract distribution INLINEFORM2 over the source text"
}