{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        },
        {
            "name": "deepspeed",
            "type": "debugpy",
            "request": "launch",
            "program": "/opt/conda/envs/adape/bin/deepspeed",
            "console": "integratedTerminal",
            "args": [
                "${workspaceFolder}/train.py",
                "--dataset_cache_dir", "./data/wikitext",
                "--output_dir", "./output/debug",
                "--config_name", "config/new_rope.json",
                "--model_name_or_path", "./output/rope_pile",
                "--max_steps",
                "100000",
                "--warmup_steps",
                "1000",
                "--lr_scheduler_type",
                "polynomial",
                "--save_steps",
                "1000",
                "--eval_steps",
                "1000",
                "--logging_steps",
                "50",
                "--weight_decay",
                "0.01",
                "--learning_rate",
                "1e-4",
                "--model_max_position_embeddings",
                "1024",
                "--per_device_train_batch_size", "2",
                "--per_device_eval_batch_size", "2",
                "--gradient_accumulation_steps",
                "2",
                "--do_train",
                "True",
                "--do_eval",
                "True",
                "--do_predict",
                "True",
                "--evaluation_strategy",
                "steps",
                "--save_strategy",
                "steps",
                "--load_best_model_at_end",
                "True",
                "--report_to",
                "tensorboard",
                "--gradient_checkpointing", "False",
                "--fp16", "True"
            ],
            "env": {
                // "DATA_DIR": "./data/pile_pg19",
                // "OUTPUT_DIR": "./output",
                // "CONFIG_NAME": "config/rope.json"
            },
        },
        {
            "name": "Evaluate",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/eval.py",
            "console": "integratedTerminal",
            "args": [
              "--dataset_cache_dir", "${workspaceFolder}/data/pile_pg19",
              "--block_size", "1024",
              "--tokenizer_name", "llama_tokenizer",
              "--per_device_eval_batch_size", "8",
              "--preprocessing_num_workers", "64",
              "--model_name_or_path", "${workspaceFolder}/output/rope_pile/"
            ],
            // "env": {
            //   "DATA_DIR": "${workspaceFolder}/data/pile",
            //   "MODEL": "${workspaceFolder}/output/ada_rope_pile/checkpoint-39000",
            //   "batch_size": "8"
            // }
          },
          {
            "name": "MM AdaPE",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/jiajun/miniconda3/envs/mllava/bin/accelerate-launch",
            "args": [
                "--config_file", "${workspaceFolder}/config/accelerate_config_zero3.yaml",
                "--num_processes", "2",
                "--main_process_port", "25045",
                "${workspaceFolder}/train_mllava.py",
                "--model_name_or_path", "TIGER-Lab/Mantis-8B-siglip-llama3-pretraind",
                "--data_config_file", "${workspaceFolder}/config/test_data.yaml",
                "--run_name", "llava_llama3_8192_adape",
                "--bf16", "True",
                "--output_dir", "output/mm-debug",
                "--num_train_epochs", "1",
                "--per_device_train_batch_size", "1",
                "--per_device_eval_batch_size", "1",
                "--gradient_accumulation_steps", "4",
                "--evaluation_strategy", "no",
                "--save_strategy", "steps",
                "--save_steps", "500",
                "--eval_steps", "500",
                "--save_total_limit", "1",
                "--learning_rate", "1e-5",
                "--weight_decay", "0.0",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "True",
                "--gradient_checkpointing", "True",
                "--dataloader_num_workers", "32",
                "--report_to", "none",
                "--do_train",
                "--tuner_type", "adape",
                "--attn_implementation", "eager",
                "--max_seq_len", "8192",
                "--mllava_type", "llava"
            ],
            "env": {
                "WANDB_DISABLED": "True",
                "CUDA_VISIBLE_DEVICES": "0,3",
            },
            "console": "integratedTerminal",
            "justMyCode": false
        },
        {
            "name": "LongLoRA",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/jiajun/miniconda3/envs/longlora/bin/torchrun",
            "args": [
            "--nproc_per_node", "auto",
            "train_longlora.py",
            "--ddp_timeout", "18000",
            "--model_name_or_path", "meta-llama/Llama-2-7b-hf",
            "--peft_type", "adape",  // 确保你在调试时替换正确的 peft_type
            "--bf16", "True",
            "--resume_from_checkpoint", "false",
            "--output_dir", "./output/longlora_llama",
            "--model_max_length", "8192",
            "--use_flash_attn", "True",
            "--per_device_train_batch_size", "1",
            "--per_device_eval_batch_size", "2",
            "--gradient_accumulation_steps", "8",
            "--evaluation_strategy", "no",
            "--save_strategy", "steps",
            "--save_steps", "200",
            "--save_total_limit", "2",
            "--learning_rate", "2e-5",
            "--weight_decay", "0.0",
            "--warmup_steps", "20",
            "--lr_scheduler_type", "constant_with_warmup",
            "--logging_steps", "1",
            "--deepspeed", "${workspaceFolder}/config/ds_configs/stage2.json",
            "--tf32", "True",
            "--max_steps", "1000",
            "--report_to", "none"
          ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "2,5,6,7",
            },
            "console": "integratedTerminal",
            "justMyCode": false
        },
        
    ]
}